{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/liujiaqi/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://github.com/312shan/Subject-and-Sentiment-Analysis\n",
    "\"\"\"\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "from capsule import *\n",
    "import jieba\n",
    "import os\n",
    "from keras.optimizers import Adam, RMSprop, SGD, Nadam\n",
    "from keras.layers import Concatenate, BatchNormalization\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "import numpy as np\n",
    "# not enable in windows\n",
    "# jieba.enable_parallel(4)\n",
    "from utils import *\n",
    "K.clear_session()\n",
    "import keras \n",
    "train_file = '../data/input/train_2.csv'\n",
    "test_file  = '../data/input/test_public_2.csv'\n",
    " \n",
    "test_size= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22452\n",
      "Found 635793 word vectors.\n"
     ]
    }
   ],
   "source": [
    "if test_size == 0:\n",
    "    stop_words = load_stop_words()\n",
    "    seqs, seqs_dev, word2index, y_train = raw_file2matrix(train_file, test_file, stop_words)\n",
    "    embeddings_index = load_embeddings_index()\n",
    "    embedding_matrix = get_embedding_matrix(word2index, embeddings_index)  # word-index-embedding是它们之间的链接关系\n",
    "    \n",
    "    X_train = np.loadtxt('../data/output/matrixes/X_train_2')\n",
    "    y_train = np.loadtxt('../data/output/matrixes/y_train_2')\n",
    "    X_test = np.loadtxt('../data/output/matrixes/X_test_2')\n",
    "    \n",
    "    # X_trains, y_trains = generate_shuffle_array(X_train, y_train)\n",
    "    \n",
    "    # drop_array(X_trains)\n",
    "\n",
    "\n",
    "else:\n",
    "    stop_words = load_stop_words()\n",
    "    seqs_train, seqs_valid, seqs_dev, word2index, y_train, y_valid, train_id_label_dict, valid_label = raw_file_2_matrix(train_file, test_file, stop_words, test_size=test_size)\n",
    "    embeddings_index = load_embeddings_index()\n",
    "    embedding_matrix = get_embedding_matrix(word2index, embeddings_index)  # word-index-embedding是它们之间的链接关系\n",
    "    X_train, X_valid, X_test = get_padding_data(seqs_train, seqs_valid, seqs_dev)  # seqs needs to be a list of a list.把列表变成矩阵，列数是embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_capsule_model():\n",
    "    maxlen = 100\n",
    "    learning_rate = 0.00001\n",
    "    input1 = Input(shape=(maxlen,))\n",
    "    embed_layer = Embedding(len(word2index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=maxlen,\n",
    "                            trainable=True)(input1)\n",
    "    embed_layer = SpatialDropout1D(rate_drop_dense)(embed_layer)\n",
    "\n",
    "    x = Bidirectional(\n",
    "        GRU(gru_len, activation='relu', dropout=dropout_p, recurrent_dropout=dropout_p, return_sequences=True))(\n",
    "        embed_layer)\n",
    "    # capsule是一个卷积网络\n",
    "    capsule = Capsule(num_capsule=Num_capsule, dim_capsule=Dim_capsule, routings=Routings,\n",
    "                      share_weights=True)(x)\n",
    "    # output_capsule = Lambda(lambda x: K.sqrt(K.sum(K.square(x), 2)))(capsule)\n",
    "    avg_pool = GlobalAveragePooling1D()(capsule)\n",
    "    max_pool = GlobalMaxPooling1D()(capsule)\n",
    "    capsule_concat  = Concatenate()([avg_pool, max_pool])\n",
    "    \n",
    "    capsule = Flatten()(capsule)\n",
    "    caspule = BatchNormalization()(capsule_concat)\n",
    "    capsule = Activation('relu')(capsule)\n",
    "    \n",
    "    capsule = Dropout(dropout_p)(capsule)\n",
    "    output = Dense(30, activation='sigmoid')(capsule)\n",
    "    model = Model(inputs=input1, outputs=output)\n",
    "    print(capsule.shape, output.shape)\n",
    "\n",
    "    adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0)\n",
    "    sgd = SGD(lr=learning_rate, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    rmsprop = RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)\n",
    "    nadam = keras.optimizers.Nadam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[f1_score])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?) (?, 30)\n",
      "Train on 28550 samples, validate on 14062 samples\n",
      "Epoch 1/30\n",
      "28550/28550 [==============================] - 705s 25ms/step - loss: 0.0346 - f1_score: 0.8280 - val_loss: 0.0283 - val_f1_score: 0.8730\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.87301, saving model to ../models/weights/capsule_weights-improvement-dataArg-01-0.8730-0.0283.hdf5\n",
      "Epoch 2/30\n",
      "28550/28550 [==============================] - 700s 25ms/step - loss: 0.0342 - f1_score: 0.8316 - val_loss: 0.0282 - val_f1_score: 0.8735\n",
      "\n",
      "Epoch 00002: val_f1_score improved from 0.87301 to 0.87354, saving model to ../models/weights/capsule_weights-improvement-dataArg-02-0.8735-0.0282.hdf5\n",
      "Epoch 3/30\n",
      "28550/28550 [==============================] - 700s 25ms/step - loss: 0.0343 - f1_score: 0.8305 - val_loss: 0.0281 - val_f1_score: 0.8739\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.87354 to 0.87389, saving model to ../models/weights/capsule_weights-improvement-dataArg-03-0.8739-0.0281.hdf5\n",
      "Epoch 4/30\n",
      "28550/28550 [==============================] - 698s 24ms/step - loss: 0.0340 - f1_score: 0.8322 - val_loss: 0.0280 - val_f1_score: 0.8747\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.87389 to 0.87474, saving model to ../models/weights/capsule_weights-improvement-dataArg-04-0.8747-0.0280.hdf5\n",
      "Epoch 5/30\n",
      "28550/28550 [==============================] - 697s 24ms/step - loss: 0.0340 - f1_score: 0.8331 - val_loss: 0.0279 - val_f1_score: 0.8749\n",
      "\n",
      "Epoch 00005: val_f1_score improved from 0.87474 to 0.87490, saving model to ../models/weights/capsule_weights-improvement-dataArg-05-0.8749-0.0279.hdf5\n",
      "Epoch 6/30\n",
      "28550/28550 [==============================] - 698s 24ms/step - loss: 0.0338 - f1_score: 0.8327 - val_loss: 0.0279 - val_f1_score: 0.8754\n",
      "\n",
      "Epoch 00006: val_f1_score improved from 0.87490 to 0.87538, saving model to ../models/weights/capsule_weights-improvement-dataArg-06-0.8754-0.0279.hdf5\n",
      "Epoch 7/30\n",
      "28550/28550 [==============================] - 695s 24ms/step - loss: 0.0338 - f1_score: 0.8318 - val_loss: 0.0278 - val_f1_score: 0.8754\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.87538 to 0.87539, saving model to ../models/weights/capsule_weights-improvement-dataArg-07-0.8754-0.0278.hdf5\n",
      "Epoch 8/30\n",
      "28550/28550 [==============================] - 699s 24ms/step - loss: 0.0340 - f1_score: 0.8301 - val_loss: 0.0278 - val_f1_score: 0.8758\n",
      "\n",
      "Epoch 00008: val_f1_score improved from 0.87539 to 0.87582, saving model to ../models/weights/capsule_weights-improvement-dataArg-08-0.8758-0.0278.hdf5\n",
      "Epoch 9/30\n",
      "28550/28550 [==============================] - 698s 24ms/step - loss: 0.0336 - f1_score: 0.8352 - val_loss: 0.0277 - val_f1_score: 0.8761\n",
      "\n",
      "Epoch 00009: val_f1_score improved from 0.87582 to 0.87614, saving model to ../models/weights/capsule_weights-improvement-dataArg-09-0.8761-0.0277.hdf5\n",
      "Epoch 10/30\n",
      "28550/28550 [==============================] - 698s 24ms/step - loss: 0.0334 - f1_score: 0.8341 - val_loss: 0.0277 - val_f1_score: 0.8763\n",
      "\n",
      "Epoch 00010: val_f1_score improved from 0.87614 to 0.87634, saving model to ../models/weights/capsule_weights-improvement-dataArg-10-0.8763-0.0277.hdf5\n",
      "Epoch 11/30\n",
      "28550/28550 [==============================] - 700s 25ms/step - loss: 0.0337 - f1_score: 0.8334 - val_loss: 0.0276 - val_f1_score: 0.8768\n",
      "\n",
      "Epoch 00011: val_f1_score improved from 0.87634 to 0.87678, saving model to ../models/weights/capsule_weights-improvement-dataArg-11-0.8768-0.0276.hdf5\n",
      "Epoch 12/30\n",
      "28550/28550 [==============================] - 700s 25ms/step - loss: 0.0338 - f1_score: 0.8332 - val_loss: 0.0276 - val_f1_score: 0.8771\n",
      "\n",
      "Epoch 00012: val_f1_score improved from 0.87678 to 0.87706, saving model to ../models/weights/capsule_weights-improvement-dataArg-12-0.8771-0.0276.hdf5\n",
      "Epoch 13/30\n",
      "28550/28550 [==============================] - 699s 24ms/step - loss: 0.0333 - f1_score: 0.8352 - val_loss: 0.0275 - val_f1_score: 0.8771\n",
      "\n",
      "Epoch 00013: val_f1_score improved from 0.87706 to 0.87714, saving model to ../models/weights/capsule_weights-improvement-dataArg-13-0.8771-0.0275.hdf5\n",
      "Epoch 14/30\n",
      "28550/28550 [==============================] - 697s 24ms/step - loss: 0.0331 - f1_score: 0.8369 - val_loss: 0.0274 - val_f1_score: 0.8769\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.87714\n",
      "Epoch 15/30\n",
      "28550/28550 [==============================] - 698s 24ms/step - loss: 0.0328 - f1_score: 0.8381 - val_loss: 0.0274 - val_f1_score: 0.8779\n",
      "\n",
      "Epoch 00015: val_f1_score improved from 0.87714 to 0.87787, saving model to ../models/weights/capsule_weights-improvement-dataArg-15-0.8779-0.0274.hdf5\n",
      "Epoch 16/30\n",
      "28550/28550 [==============================] - 701s 25ms/step - loss: 0.0329 - f1_score: 0.8381 - val_loss: 0.0273 - val_f1_score: 0.8781\n",
      "\n",
      "Epoch 00016: val_f1_score improved from 0.87787 to 0.87814, saving model to ../models/weights/capsule_weights-improvement-dataArg-16-0.8781-0.0273.hdf5\n",
      "Epoch 17/30\n",
      "28550/28550 [==============================] - 700s 25ms/step - loss: 0.0332 - f1_score: 0.8359 - val_loss: 0.0273 - val_f1_score: 0.8783\n",
      "\n",
      "Epoch 00017: val_f1_score improved from 0.87814 to 0.87830, saving model to ../models/weights/capsule_weights-improvement-dataArg-17-0.8783-0.0273.hdf5\n",
      "Epoch 18/30\n",
      "28550/28550 [==============================] - 704s 25ms/step - loss: 0.0331 - f1_score: 0.8363 - val_loss: 0.0272 - val_f1_score: 0.8796\n",
      "\n",
      "Epoch 00018: val_f1_score improved from 0.87830 to 0.87957, saving model to ../models/weights/capsule_weights-improvement-dataArg-18-0.8796-0.0272.hdf5\n",
      "Epoch 19/30\n",
      "28550/28550 [==============================] - 703s 25ms/step - loss: 0.0327 - f1_score: 0.8387 - val_loss: 0.0272 - val_f1_score: 0.8796\n",
      "\n",
      "Epoch 00019: val_f1_score improved from 0.87957 to 0.87961, saving model to ../models/weights/capsule_weights-improvement-dataArg-19-0.8796-0.0272.hdf5\n",
      "Epoch 20/30\n",
      "28550/28550 [==============================] - 703s 25ms/step - loss: 0.0329 - f1_score: 0.8367 - val_loss: 0.0271 - val_f1_score: 0.8800\n",
      "\n",
      "Epoch 00020: val_f1_score improved from 0.87961 to 0.88004, saving model to ../models/weights/capsule_weights-improvement-dataArg-20-0.8800-0.0271.hdf5\n",
      "Epoch 21/30\n",
      "28550/28550 [==============================] - 700s 25ms/step - loss: 0.0327 - f1_score: 0.8398 - val_loss: 0.0271 - val_f1_score: 0.8800\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.88004\n",
      "Epoch 22/30\n",
      "28550/28550 [==============================] - 686s 24ms/step - loss: 0.0330 - f1_score: 0.8384 - val_loss: 0.0270 - val_f1_score: 0.8799\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.88004\n",
      "Epoch 23/30\n",
      "28550/28550 [==============================] - 691s 24ms/step - loss: 0.0327 - f1_score: 0.8391 - val_loss: 0.0270 - val_f1_score: 0.8798\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.88004\n",
      "Epoch 24/30\n",
      "28550/28550 [==============================] - 698s 24ms/step - loss: 0.0327 - f1_score: 0.8392 - val_loss: 0.0270 - val_f1_score: 0.8798\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.88004\n",
      "Epoch 25/30\n",
      "28550/28550 [==============================] - 699s 24ms/step - loss: 0.0326 - f1_score: 0.8407 - val_loss: 0.0269 - val_f1_score: 0.8799\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.88004\n",
      "Epoch 26/30\n",
      "28550/28550 [==============================] - 697s 24ms/step - loss: 0.0323 - f1_score: 0.8421 - val_loss: 0.0269 - val_f1_score: 0.8804\n",
      "\n",
      "Epoch 00026: val_f1_score improved from 0.88004 to 0.88044, saving model to ../models/weights/capsule_weights-improvement-dataArg-26-0.8804-0.0269.hdf5\n",
      "Epoch 27/30\n",
      "28550/28550 [==============================] - 697s 24ms/step - loss: 0.0323 - f1_score: 0.8408 - val_loss: 0.0269 - val_f1_score: 0.8808\n",
      "\n",
      "Epoch 00027: val_f1_score improved from 0.88044 to 0.88082, saving model to ../models/weights/capsule_weights-improvement-dataArg-27-0.8808-0.0269.hdf5\n",
      "Epoch 28/30\n",
      "28550/28550 [==============================] - 691s 24ms/step - loss: 0.0322 - f1_score: 0.8413 - val_loss: 0.0268 - val_f1_score: 0.8810\n",
      "\n",
      "Epoch 00028: val_f1_score improved from 0.88082 to 0.88104, saving model to ../models/weights/capsule_weights-improvement-dataArg-28-0.8810-0.0268.hdf5\n",
      "Epoch 29/30\n",
      "28550/28550 [==============================] - 696s 24ms/step - loss: 0.0325 - f1_score: 0.8413 - val_loss: 0.0268 - val_f1_score: 0.8809\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.88104\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28550/28550 [==============================] - 698s 24ms/step - loss: 0.0319 - f1_score: 0.8419 - val_loss: 0.0267 - val_f1_score: 0.8815\n",
      "\n",
      "Epoch 00030: val_f1_score improved from 0.88104 to 0.88146, saving model to ../models/weights/capsule_weights-improvement-dataArg-30-0.8815-0.0267.hdf5\n",
      "(?, ?) (?, 30)\n",
      "Train on 28550 samples, validate on 14062 samples\n",
      "Epoch 1/30\n",
      "28550/28550 [==============================] - 714s 25ms/step - loss: 0.0347 - f1_score: 0.8274 - val_loss: 0.0283 - val_f1_score: 0.8731\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.87313, saving model to ../models/weights/capsule_weights-improvement-dataArg-01-0.8731-0.0283.hdf5\n",
      "Epoch 2/30\n",
      "28550/28550 [==============================] - 698s 24ms/step - loss: 0.0342 - f1_score: 0.8306 - val_loss: 0.0282 - val_f1_score: 0.8736\n",
      "\n",
      "Epoch 00002: val_f1_score improved from 0.87313 to 0.87359, saving model to ../models/weights/capsule_weights-improvement-dataArg-02-0.8736-0.0282.hdf5\n",
      "Epoch 3/30\n",
      "28550/28550 [==============================] - 698s 24ms/step - loss: 0.0342 - f1_score: 0.8299 - val_loss: 0.0281 - val_f1_score: 0.8743\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.87359 to 0.87425, saving model to ../models/weights/capsule_weights-improvement-dataArg-03-0.8743-0.0281.hdf5\n",
      "Epoch 4/30\n",
      "28550/28550 [==============================] - 700s 25ms/step - loss: 0.0345 - f1_score: 0.8298 - val_loss: 0.0280 - val_f1_score: 0.8744\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.87425 to 0.87440, saving model to ../models/weights/capsule_weights-improvement-dataArg-04-0.8744-0.0280.hdf5\n",
      "Epoch 5/30\n",
      "28550/28550 [==============================] - 700s 25ms/step - loss: 0.0337 - f1_score: 0.8349 - val_loss: 0.0279 - val_f1_score: 0.8750\n",
      "\n",
      "Epoch 00005: val_f1_score improved from 0.87440 to 0.87504, saving model to ../models/weights/capsule_weights-improvement-dataArg-05-0.8750-0.0279.hdf5\n",
      "Epoch 6/30\n",
      "28550/28550 [==============================] - 700s 25ms/step - loss: 0.0341 - f1_score: 0.8318 - val_loss: 0.0279 - val_f1_score: 0.8754\n",
      "\n",
      "Epoch 00006: val_f1_score improved from 0.87504 to 0.87545, saving model to ../models/weights/capsule_weights-improvement-dataArg-06-0.8754-0.0279.hdf5\n",
      "Epoch 7/30\n",
      "28550/28550 [==============================] - 701s 25ms/step - loss: 0.0339 - f1_score: 0.8322 - val_loss: 0.0278 - val_f1_score: 0.8756\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.87545 to 0.87561, saving model to ../models/weights/capsule_weights-improvement-dataArg-07-0.8756-0.0278.hdf5\n",
      "Epoch 8/30\n",
      "28550/28550 [==============================] - 620s 22ms/step - loss: 0.0336 - f1_score: 0.8323 - val_loss: 0.0277 - val_f1_score: 0.8758\n",
      "\n",
      "Epoch 00008: val_f1_score improved from 0.87561 to 0.87576, saving model to ../models/weights/capsule_weights-improvement-dataArg-08-0.8758-0.0277.hdf5\n",
      "Epoch 9/30\n",
      "28550/28550 [==============================] - 618s 22ms/step - loss: 0.0338 - f1_score: 0.8319 - val_loss: 0.0277 - val_f1_score: 0.8764\n",
      "\n",
      "Epoch 00009: val_f1_score improved from 0.87576 to 0.87642, saving model to ../models/weights/capsule_weights-improvement-dataArg-09-0.8764-0.0277.hdf5\n",
      "Epoch 10/30\n",
      "28550/28550 [==============================] - 618s 22ms/step - loss: 0.0335 - f1_score: 0.8330 - val_loss: 0.0276 - val_f1_score: 0.8766\n",
      "\n",
      "Epoch 00010: val_f1_score improved from 0.87642 to 0.87657, saving model to ../models/weights/capsule_weights-improvement-dataArg-10-0.8766-0.0276.hdf5\n",
      "Epoch 11/30\n",
      "28550/28550 [==============================] - 620s 22ms/step - loss: 0.0334 - f1_score: 0.8341 - val_loss: 0.0276 - val_f1_score: 0.8770\n",
      "\n",
      "Epoch 00011: val_f1_score improved from 0.87657 to 0.87698, saving model to ../models/weights/capsule_weights-improvement-dataArg-11-0.8770-0.0276.hdf5\n",
      "Epoch 12/30\n",
      "28550/28550 [==============================] - 616s 22ms/step - loss: 0.0335 - f1_score: 0.8360 - val_loss: 0.0275 - val_f1_score: 0.8774\n",
      "\n",
      "Epoch 00012: val_f1_score improved from 0.87698 to 0.87738, saving model to ../models/weights/capsule_weights-improvement-dataArg-12-0.8774-0.0275.hdf5\n",
      "Epoch 13/30\n",
      "28550/28550 [==============================] - 618s 22ms/step - loss: 0.0334 - f1_score: 0.8343 - val_loss: 0.0275 - val_f1_score: 0.8781\n",
      "\n",
      "Epoch 00013: val_f1_score improved from 0.87738 to 0.87810, saving model to ../models/weights/capsule_weights-improvement-dataArg-13-0.8781-0.0275.hdf5\n",
      "Epoch 14/30\n",
      "28550/28550 [==============================] - 589s 21ms/step - loss: 0.0330 - f1_score: 0.8370 - val_loss: 0.0274 - val_f1_score: 0.8783\n",
      "\n",
      "Epoch 00014: val_f1_score improved from 0.87810 to 0.87830, saving model to ../models/weights/capsule_weights-improvement-dataArg-14-0.8783-0.0274.hdf5\n",
      "Epoch 15/30\n",
      "28550/28550 [==============================] - 536s 19ms/step - loss: 0.0335 - f1_score: 0.8339 - val_loss: 0.0274 - val_f1_score: 0.8786\n",
      "\n",
      "Epoch 00015: val_f1_score improved from 0.87830 to 0.87863, saving model to ../models/weights/capsule_weights-improvement-dataArg-15-0.8786-0.0274.hdf5\n",
      "Epoch 16/30\n",
      "28550/28550 [==============================] - 538s 19ms/step - loss: 0.0330 - f1_score: 0.8362 - val_loss: 0.0273 - val_f1_score: 0.8785\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.87863\n",
      "Epoch 17/30\n",
      "28550/28550 [==============================] - 538s 19ms/step - loss: 0.0333 - f1_score: 0.8359 - val_loss: 0.0273 - val_f1_score: 0.8787\n",
      "\n",
      "Epoch 00017: val_f1_score improved from 0.87863 to 0.87868, saving model to ../models/weights/capsule_weights-improvement-dataArg-17-0.8787-0.0273.hdf5\n",
      "Epoch 18/30\n",
      "28550/28550 [==============================] - 534s 19ms/step - loss: 0.0327 - f1_score: 0.8395 - val_loss: 0.0272 - val_f1_score: 0.8791\n",
      "\n",
      "Epoch 00018: val_f1_score improved from 0.87868 to 0.87908, saving model to ../models/weights/capsule_weights-improvement-dataArg-18-0.8791-0.0272.hdf5\n",
      "Epoch 19/30\n",
      "28550/28550 [==============================] - 535s 19ms/step - loss: 0.0327 - f1_score: 0.8379 - val_loss: 0.0271 - val_f1_score: 0.8792\n",
      "\n",
      "Epoch 00019: val_f1_score improved from 0.87908 to 0.87917, saving model to ../models/weights/capsule_weights-improvement-dataArg-19-0.8792-0.0271.hdf5\n",
      "Epoch 20/30\n",
      "28550/28550 [==============================] - 536s 19ms/step - loss: 0.0330 - f1_score: 0.8381 - val_loss: 0.0271 - val_f1_score: 0.8792\n",
      "\n",
      "Epoch 00020: val_f1_score improved from 0.87917 to 0.87919, saving model to ../models/weights/capsule_weights-improvement-dataArg-20-0.8792-0.0271.hdf5\n",
      "Epoch 21/30\n",
      "28550/28550 [==============================] - 536s 19ms/step - loss: 0.0329 - f1_score: 0.8361 - val_loss: 0.0270 - val_f1_score: 0.8800\n",
      "\n",
      "Epoch 00021: val_f1_score improved from 0.87919 to 0.87999, saving model to ../models/weights/capsule_weights-improvement-dataArg-21-0.8800-0.0270.hdf5\n",
      "Epoch 22/30\n",
      "28550/28550 [==============================] - 537s 19ms/step - loss: 0.0331 - f1_score: 0.8355 - val_loss: 0.0270 - val_f1_score: 0.8806\n",
      "\n",
      "Epoch 00022: val_f1_score improved from 0.87999 to 0.88065, saving model to ../models/weights/capsule_weights-improvement-dataArg-22-0.8806-0.0270.hdf5\n",
      "Epoch 23/30\n",
      "28550/28550 [==============================] - 499s 17ms/step - loss: 0.0326 - f1_score: 0.8393 - val_loss: 0.0270 - val_f1_score: 0.8810\n",
      "\n",
      "Epoch 00023: val_f1_score improved from 0.88065 to 0.88097, saving model to ../models/weights/capsule_weights-improvement-dataArg-23-0.8810-0.0270.hdf5\n",
      "Epoch 24/30\n",
      "28550/28550 [==============================] - 493s 17ms/step - loss: 0.0324 - f1_score: 0.8406 - val_loss: 0.0269 - val_f1_score: 0.8809\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.88097\n",
      "Epoch 25/30\n",
      "28550/28550 [==============================] - 490s 17ms/step - loss: 0.0326 - f1_score: 0.8393 - val_loss: 0.0269 - val_f1_score: 0.8812\n",
      "\n",
      "Epoch 00025: val_f1_score improved from 0.88097 to 0.88119, saving model to ../models/weights/capsule_weights-improvement-dataArg-25-0.8812-0.0269.hdf5\n",
      "Epoch 26/30\n",
      "28550/28550 [==============================] - 441s 15ms/step - loss: 0.0324 - f1_score: 0.8400 - val_loss: 0.0268 - val_f1_score: 0.8813\n",
      "\n",
      "Epoch 00026: val_f1_score improved from 0.88119 to 0.88125, saving model to ../models/weights/capsule_weights-improvement-dataArg-26-0.8813-0.0268.hdf5\n",
      "Epoch 27/30\n",
      "28550/28550 [==============================] - 439s 15ms/step - loss: 0.0324 - f1_score: 0.8413 - val_loss: 0.0268 - val_f1_score: 0.8814\n",
      "\n",
      "Epoch 00027: val_f1_score improved from 0.88125 to 0.88142, saving model to ../models/weights/capsule_weights-improvement-dataArg-27-0.8814-0.0268.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "28550/28550 [==============================] - 439s 15ms/step - loss: 0.0323 - f1_score: 0.8423 - val_loss: 0.0268 - val_f1_score: 0.8812\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.88142\n",
      "Epoch 29/30\n",
      "28550/28550 [==============================] - 441s 15ms/step - loss: 0.0322 - f1_score: 0.8415 - val_loss: 0.0267 - val_f1_score: 0.8814\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.88142\n",
      "Epoch 30/30\n",
      "28550/28550 [==============================] - 438s 15ms/step - loss: 0.0323 - f1_score: 0.8415 - val_loss: 0.0267 - val_f1_score: 0.8819\n",
      "\n",
      "Epoch 00030: val_f1_score improved from 0.88142 to 0.88188, saving model to ../models/weights/capsule_weights-improvement-dataArg-30-0.8819-0.0267.hdf5\n",
      "(?, ?) (?, 30)\n",
      "Train on 28550 samples, validate on 14062 samples\n",
      "Epoch 1/30\n",
      "28550/28550 [==============================] - 431s 15ms/step - loss: 0.0344 - f1_score: 0.8300 - val_loss: 0.0283 - val_f1_score: 0.8733\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.87326, saving model to ../models/weights/capsule_weights-improvement-dataArg-01-0.8733-0.0283.hdf5\n",
      "Epoch 2/30\n",
      "28550/28550 [==============================] - 422s 15ms/step - loss: 0.0340 - f1_score: 0.8320 - val_loss: 0.0282 - val_f1_score: 0.8737\n",
      "\n",
      "Epoch 00002: val_f1_score improved from 0.87326 to 0.87366, saving model to ../models/weights/capsule_weights-improvement-dataArg-02-0.8737-0.0282.hdf5\n",
      "Epoch 3/30\n",
      "28550/28550 [==============================] - 424s 15ms/step - loss: 0.0344 - f1_score: 0.8287 - val_loss: 0.0281 - val_f1_score: 0.8744\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.87366 to 0.87437, saving model to ../models/weights/capsule_weights-improvement-dataArg-03-0.8744-0.0281.hdf5\n",
      "Epoch 4/30\n",
      "28550/28550 [==============================] - 424s 15ms/step - loss: 0.0340 - f1_score: 0.8327 - val_loss: 0.0280 - val_f1_score: 0.8753\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.87437 to 0.87528, saving model to ../models/weights/capsule_weights-improvement-dataArg-04-0.8753-0.0280.hdf5\n",
      "Epoch 5/30\n",
      "28550/28550 [==============================] - 438s 15ms/step - loss: 0.0341 - f1_score: 0.8309 - val_loss: 0.0279 - val_f1_score: 0.8750\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.87528\n",
      "Epoch 6/30\n",
      "28550/28550 [==============================] - 441s 15ms/step - loss: 0.0338 - f1_score: 0.8331 - val_loss: 0.0279 - val_f1_score: 0.8752\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.87528\n",
      "Epoch 7/30\n",
      "28550/28550 [==============================] - 440s 15ms/step - loss: 0.0338 - f1_score: 0.8313 - val_loss: 0.0278 - val_f1_score: 0.8759\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.87528 to 0.87587, saving model to ../models/weights/capsule_weights-improvement-dataArg-07-0.8759-0.0278.hdf5\n",
      "Epoch 8/30\n",
      "28550/28550 [==============================] - 440s 15ms/step - loss: 0.0337 - f1_score: 0.8316 - val_loss: 0.0277 - val_f1_score: 0.8758\n",
      "\n",
      "Epoch 00008: val_f1_score did not improve from 0.87587\n",
      "Epoch 9/30\n",
      "28550/28550 [==============================] - 441s 15ms/step - loss: 0.0338 - f1_score: 0.8341 - val_loss: 0.0277 - val_f1_score: 0.8762\n",
      "\n",
      "Epoch 00009: val_f1_score improved from 0.87587 to 0.87625, saving model to ../models/weights/capsule_weights-improvement-dataArg-09-0.8762-0.0277.hdf5\n",
      "Epoch 10/30\n",
      "28550/28550 [==============================] - 441s 15ms/step - loss: 0.0339 - f1_score: 0.8328 - val_loss: 0.0276 - val_f1_score: 0.8766\n",
      "\n",
      "Epoch 00010: val_f1_score improved from 0.87625 to 0.87659, saving model to ../models/weights/capsule_weights-improvement-dataArg-10-0.8766-0.0276.hdf5\n",
      "Epoch 11/30\n",
      "28550/28550 [==============================] - 440s 15ms/step - loss: 0.0336 - f1_score: 0.8336 - val_loss: 0.0276 - val_f1_score: 0.8771\n",
      "\n",
      "Epoch 00011: val_f1_score improved from 0.87659 to 0.87706, saving model to ../models/weights/capsule_weights-improvement-dataArg-11-0.8771-0.0276.hdf5\n",
      "Epoch 12/30\n",
      "28550/28550 [==============================] - 441s 15ms/step - loss: 0.0334 - f1_score: 0.8345 - val_loss: 0.0275 - val_f1_score: 0.8772\n",
      "\n",
      "Epoch 00012: val_f1_score improved from 0.87706 to 0.87725, saving model to ../models/weights/capsule_weights-improvement-dataArg-12-0.8772-0.0275.hdf5\n",
      "Epoch 13/30\n",
      "28550/28550 [==============================] - 365s 13ms/step - loss: 0.0332 - f1_score: 0.8364 - val_loss: 0.0275 - val_f1_score: 0.8784\n",
      "\n",
      "Epoch 00013: val_f1_score improved from 0.87725 to 0.87843, saving model to ../models/weights/capsule_weights-improvement-dataArg-13-0.8784-0.0275.hdf5\n",
      "Epoch 14/30\n",
      "24336/28550 [========================>.....] - ETA: 44s - loss: 0.0332 - f1_score: 0.8368"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4a9773db7e22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m               validation_split=0.33)  # batch_size: 16, epochs = 24\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 0.6363  0.065\n",
    "for _ in range(5):\n",
    "    filepath=\"../models/weights/capsule_weights-improvement-dataArg-{epoch:02d}-{val_f1_score:.4f}-{val_loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True,\n",
    "    mode='max')\n",
    "    model = get_capsule_model()\n",
    "    model.load_weights('../models/weights/capsule_weights-improvement-dataArg-39-0.8726-0.0285.hdf5')\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=30, shuffle=True, \n",
    "              verbose=1, \n",
    "              callbacks=[checkpoint], \n",
    "              validation_split=0.33)  # batch_size: 16, epochs = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?) (?, 30)\n"
     ]
    }
   ],
   "source": [
    "model = get_capsule_model()\n",
    "model.load_weights('../models/weights/capsule_weights-improvement-dataArg-09-0.7074-0.0527.hdf5') # 0.60\n",
    "pred4 = model.predict(X_test, batch_size=1024)\n",
    "\n",
    "# np.savetxt('../data/output/capsule_6454_1106.txt', pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, res_df = pred2res(pred4)\n",
    "res_df.head(100)\n",
    "res_df.to_csv('../data/output/submission/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
