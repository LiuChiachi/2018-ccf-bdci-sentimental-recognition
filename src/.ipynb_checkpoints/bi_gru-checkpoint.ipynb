{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/liujiaqi/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"https://github.com/312shan/Subject-and-Sentiment-Analysis\"\"\"\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "from capsule import *\n",
    "import jieba\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalMaxPooling1D, MaxPooling1D, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Dropout, Activation, SpatialDropout1D\n",
    "from keras.layers import Input, Bidirectional, RNN, Concatenate,  Flatten\n",
    "from keras.layers.pooling import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from keras.layers import Permute, Reshape, merge\n",
    "K.clear_session()\n",
    "import keras \n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))\n",
    "train_file = '../data/input/train_2.csv'\n",
    "test_file  = '../data/input/test_public_2.csv'\n",
    "test_size = 0# .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.874 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22452\n",
      "Found 635793 word vectors.\n"
     ]
    }
   ],
   "source": [
    "if test_size == 0:\n",
    "    stop_words = load_stop_words()\n",
    "    seqs, seqs_dev, word2index, y_train = raw_file2matrix(train_file, test_file, stop_words)\n",
    "    embeddings_index = load_embeddings_index()\n",
    "    embedding_matrix = get_embedding_matrix(word2index, embeddings_index)  # word-index-embedding是它们之间的链接关系\n",
    "    \n",
    "    X_train = np.loadtxt('../data/output/matrixes/X_train_2')\n",
    "    y_train = np.loadtxt('../data/output/matrixes/y_train_2')\n",
    "    X_test = np.loadtxt('../data/output/matrixes/X_test_2')\n",
    "   \n",
    "    # X_trains, y_trains = generate_shuffle_array(X_train, y_train)\n",
    "    \n",
    "    # drop_array(X_trains)\n",
    "\n",
    "        \n",
    "else:\n",
    "    stop_words = load_stop_words()\n",
    "    seqs_train, seqs_valid, seqs_dev, word2index, y_train, y_valid, train_id_label_dict, valid_label = raw_file_2_matrix(train_file, test_file, stop_words, test_size=test_size)\n",
    "    embeddings_index = load_embeddings_index()\n",
    "    embedding_matrix = get_embedding_matrix(word2index, embeddings_index)  # word-index-embedding是它们之间的链接关系\n",
    "    X_train, X_valid, X_test = get_padding_data(seqs_train, seqs_valid, seqs_dev)  # seqs needs to be a list of a list.把列表变成矩阵，列数是embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "    # https://github.com/keras-team/keras/issues/1472\n",
    "    # https://github.com/philipperemy/keras-attention-mechanism\n",
    "    TIME_STEPS = 20\n",
    "    INPUT_DIM = 2\n",
    "    # if True, the attention vector is shared across the input_dimensions where the attention is applied.\n",
    "    SINGLE_ATTENTION_VECTOR = False\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    # print(a.shape, input_dim, TIME_STEPS)\n",
    "    # a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    # a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    a_probs = Permute((2, 1))(a)\n",
    "    # print(inputs.shape, a_probs.shape)\n",
    "    # output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    output_attention_mul = Concatenate(axis=1)([inputs, a_probs])\n",
    "    return output_attention_mul\n",
    "\n",
    "    \"\"\"\n",
    "    # https://stackoverflow.com/questions/42918446/how-to-add-an-attention-mechanism-in-keras\n",
    "    activations = LSTM(units, return_sequences=True)(embedded)\n",
    "\n",
    "    # compute importance for each step\n",
    "    attention = Dense(1, activation='tanh')(activations)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation('softmax')(attention)\n",
    "    attention = RepeatVector(units)(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "\n",
    "    sent_representation = merge([activations, attention], mode='mul')\n",
    "    \"\"\"\n",
    "def model_attention_applied_after_lstm():\n",
    "    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "    lstm_units = 32\n",
    "    lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n",
    "    \n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "    \"\"\"\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "def get_bi_gru_model():\n",
    "    # 3个串联  0.10\n",
    "    drop = 0.60# 0.55\n",
    "    # dropout_p = 0.5\n",
    "    learning_rate = 0.001  # 0.0001\n",
    "    gru_units= 128  # 100\n",
    "    maxlen = 100\n",
    "    inputs = Input(shape=(maxlen,))\n",
    "    embed_layer = Embedding(len(word2index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "                            input_length=maxlen, trainable=True)(inputs)\n",
    "    embed_layer = SpatialDropout1D(drop)(embed_layer)\n",
    "    \"\"\"x = LSTM(output_dim=100,activation='relu',inner_activation='relu', return_sequences=True)(x)\"\"\"\n",
    "    x1 = Bidirectional(GRU(gru_units, activation='relu', dropout=dropout_p, recurrent_dropout=dropout_p, \n",
    "                          return_sequences=True))(embed_layer)\n",
    "    x1 = attention_3d_block(x1)\n",
    "    x2 = Bidirectional(GRU(gru_units, activation='relu', dropout=dropout_p, recurrent_dropout=dropout_p, \n",
    "                      return_sequences=True))(embed_layer) \n",
    "    \n",
    "    x2 = attention_3d_block(x2)\n",
    "    x3 = Concatenate(axis=1)([x1, x2])\n",
    "    avg_pool = GlobalAveragePooling1D()(x3)\n",
    "    max_pool = GlobalMaxPooling1D()(x3)\n",
    "    # print(avg_pool.shape, max_pool.shape)\n",
    "    x5 = Concatenate(axis=1)([avg_pool, max_pool])\n",
    "    \n",
    "    fc = Dense(300)(x5)\n",
    "    bn = BatchNormalization()(fc)\n",
    "    bn = Activation('relu')(bn)\n",
    "    bn_dropout = Dropout(drop)(bn)\n",
    "    # bn_dropout = Flatten()(bn_dropout)\n",
    "    outputs = Dense(30, activation='sigmoid')(bn_dropout)\n",
    "    # print(outputs.shape)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    sgd = SGD(lr=learning_rate, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    rmsprop = RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)\n",
    "    nadam = keras.optimizers.Nadam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[f1_score])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7137 samples, validate on 3516 samples\n",
      "Epoch 1/60\n",
      "7137/7137 [==============================] - 154s 22ms/step - loss: 0.0670 - f1_score: 0.6244 - val_loss: 0.0437 - val_f1_score: 0.7269\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.72691, saving model to ../models/weights/bi_gru_attention-01-0.7269-0.0437.hdf5\n",
      "Epoch 2/60\n",
      "7137/7137 [==============================] - 115s 16ms/step - loss: 0.0657 - f1_score: 0.6356 - val_loss: 0.0446 - val_f1_score: 0.7206\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.72691\n",
      "Epoch 3/60\n",
      "7137/7137 [==============================] - 112s 16ms/step - loss: 0.0658 - f1_score: 0.6365 - val_loss: 0.0452 - val_f1_score: 0.7186\n",
      "\n",
      "Epoch 00003: val_f1_score did not improve from 0.72691\n",
      "Epoch 4/60\n",
      "7137/7137 [==============================] - 111s 16ms/step - loss: 0.0652 - f1_score: 0.6409 - val_loss: 0.0459 - val_f1_score: 0.7231\n",
      "\n",
      "Epoch 00004: val_f1_score did not improve from 0.72691\n",
      "Epoch 5/60\n",
      "7137/7137 [==============================] - 137s 19ms/step - loss: 0.0643 - f1_score: 0.6451 - val_loss: 0.0463 - val_f1_score: 0.7103\n",
      "\n",
      "Epoch 00005: val_f1_score did not improve from 0.72691\n",
      "Epoch 6/60\n",
      "7137/7137 [==============================] - 148s 21ms/step - loss: 0.0641 - f1_score: 0.6458 - val_loss: 0.0463 - val_f1_score: 0.7130\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.72691\n",
      "Epoch 7/60\n",
      "7137/7137 [==============================] - 107s 15ms/step - loss: 0.0642 - f1_score: 0.6417 - val_loss: 0.0471 - val_f1_score: 0.7132\n",
      "\n",
      "Epoch 00007: val_f1_score did not improve from 0.72691\n",
      "Epoch 8/60\n",
      "2576/7137 [=========>....................] - ETA: 52s - loss: 0.0629 - f1_score: 0.6541"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-316bd4ba4f5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     model.fit(X_train, y_train, batch_size=16, epochs=60, shuffle=True, \n\u001b[1;32m     11\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                         validation_split=0.33)  # batch_size: 16, epochs = 40\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    model = get_bi_gru_model()\n",
    "    model.load_weights('../models/weights/bi_gru_attention-dataArg-28-0.7395-0.0458.hdf5')\n",
    "\n",
    "    # log_filepath = './tmp/log' \n",
    "    filepath=\"../models/weights/bi_gru_attention-{epoch:02d}-{val_f1_score:.4f}-{val_loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True,\n",
    "    mode='max')\n",
    "    # callback = [keras.callbacks.TensorBoard(log_dir=log_filepath, write_images=1, histogram_freq=1) ]\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=60, shuffle=True, \n",
    "              callbacks=[checkpoint], \n",
    "                        validation_split=0.33)  # batch_size: 16, epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "model= get_bi_gru_model()\n",
    "model.load_weights('../models/weights/bi_gru_attention-01-0.7269-0.0437.hdf5')\n",
    "pred4 = model.predict(X_test, batch_size=1024)\n",
    " \n",
    "# res, res_df = pred2res(pred4)\n",
    "np.savetxt('../data/output/bi_gru_7269_437_1110.txt', pred4)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
