{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/liujiaqi/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 635793 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.086 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19878\n",
      "(8288, 100) (2364, 100) (8288, 30)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://github.com/312shan/Subject-and-Sentiment-Analysis\n",
    "\"\"\"\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "from capsule import *\n",
    "import jieba\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, SpatialDropout2D, Activation, Embedding, Flatten, Conv2D, MaxPool2D\n",
    " \n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Reshape, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import numpy as np\n",
    "from keras.layers import BatchNormalization\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "test_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_size == 0:\n",
    "    X_train = '../data/output/matrixes/X_train'\n",
    "    y_train = '../data/output/matrixes/y_train'\n",
    "    X_test = '../data/output/matrixes/X_dev'\n",
    "\n",
    "else:\n",
    "    stop_words = load_stop_words()\n",
    "    embeddings_index = load_embeddings_index()\n",
    "    embedding_matrix = get_embedding_matrix(word2index, embeddings_index)  # word-index-embedding是它们之间的链接关系\n",
    "    seqs_train, seqs_valid, seqs_dev, word2index, y_train, y_valid, train_id_label_dict, valid_label = raw_file_2_matrix(train_file, test_file, stop_words, test_size=test_size)\n",
    "    X_train, X_valid, X_test = get_padding_data(seqs_train, seqs_valid, seqs_dev)  # seqs needs to be a list of a list.把列表变成矩阵，列数是embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hi_text_cnn_model():\n",
    "    drop = 0.60 \n",
    "    # dropout_p = 0.5\n",
    "    learning_rate = 0.005  # 0.0001\n",
    "    inputs = Input(shape=(maxlen,))\n",
    "    embed_layer = Embedding(len(word2index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "                            input_length=maxlen, trainable=False)(inputs)\n",
    "    embed_layer = SpatialDropout1D(drop)(embed_layer)\n",
    "     \n",
    "    # 第一条支路：\n",
    "    capsule1 = Capsule(num_capsule=Num_capsule, dim_capsule=Dim_capsule, routings=Routings, # kernel_size=(3, 1),\n",
    "                      share_weights=True)(embed_layer)\n",
    "    bn1 = BatchNormalization()(capsule1)\n",
    "                                          \n",
    "    # 第二条支路：   \n",
    "    capsule2 = Capsule(num_capsule=Num_capsule, dim_capsule=Dim_capsule, routings=Routings, # kernel_size=(3, 1),\n",
    "                      share_weights=True)(embed_layer)\n",
    "    bn2 = BatchNormalization()(capsule2)\n",
    "           \n",
    "    capsule3 = Capsule(num_capsule=Num_capsule, dim_capsule=Dim_capsule, routings=Routings, # kernel_size=(3, 1),\n",
    "                      share_weights=True)(bn2)  \n",
    "    bn3 = BatchNormalization()(capsule3)\n",
    "   \n",
    "    # concat, fc+bn+relu\n",
    "    bn = Concatenate(axis=1)([bn1, bn3])\n",
    "    bn = Flatten()(bn)\n",
    "\n",
    "    fc = Dense(300)(bn)\n",
    "    bn = BatchNormalization()(fc)\n",
    "    bn = Activation('relu')(bn)\n",
    "    bn_dropout = Dropout(drop)(bn)\n",
    "    outputs = Dense(30, activation=\"sigmoid\")(bn_dropout)\n",
    "    print(outputs.shape)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "    # validation_data=(p_X_test, p_y_test))\n",
    "    # score, acc = model.evaluate(p_X_test, p_y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 30)\n",
      "Epoch 1/36\n",
      "8288/8288 [==============================] - 21s 3ms/step - loss: 0.2067 - acc: 0.9370\n",
      "Epoch 2/36\n",
      "8288/8288 [==============================] - 12s 1ms/step - loss: 0.1433 - acc: 0.9618\n",
      "Epoch 3/36\n",
      "8288/8288 [==============================] - 12s 1ms/step - loss: 0.1232 - acc: 0.9648\n",
      "Epoch 4/36\n",
      "8288/8288 [==============================] - 11s 1ms/step - loss: 0.1131 - acc: 0.9659\n",
      "Epoch 5/36\n",
      "8288/8288 [==============================] - 13s 2ms/step - loss: 0.1070 - acc: 0.9666\n",
      "Epoch 6/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1024 - acc: 0.9671\n",
      "Epoch 7/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1002 - acc: 0.9674\n",
      "Epoch 8/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0977 - acc: 0.9675\n",
      "Epoch 9/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0961 - acc: 0.9677\n",
      "Epoch 10/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0945 - acc: 0.9684\n",
      "Epoch 11/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0930 - acc: 0.9687\n",
      "Epoch 12/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0917 - acc: 0.9688\n",
      "Epoch 13/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0908 - acc: 0.9689\n",
      "Epoch 14/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0896 - acc: 0.9690\n",
      "Epoch 15/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0886 - acc: 0.9691\n",
      "Epoch 16/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0889 - acc: 0.9690\n",
      "Epoch 17/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0875 - acc: 0.9693\n",
      "Epoch 18/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0876 - acc: 0.9693\n",
      "Epoch 19/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0861 - acc: 0.9696\n",
      "Epoch 20/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0861 - acc: 0.9693\n",
      "Epoch 21/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0857 - acc: 0.9696\n",
      "Epoch 22/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0852 - acc: 0.9696\n",
      "Epoch 23/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0855 - acc: 0.9695\n",
      "Epoch 24/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0839 - acc: 0.9700\n",
      "Epoch 25/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0843 - acc: 0.9699\n",
      "Epoch 26/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0841 - acc: 0.9697\n",
      "Epoch 27/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0831 - acc: 0.9700\n",
      "Epoch 28/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0831 - acc: 0.9698\n",
      "Epoch 29/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0829 - acc: 0.9702\n",
      "Epoch 30/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0824 - acc: 0.9704\n",
      "Epoch 31/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0827 - acc: 0.9704\n",
      "Epoch 32/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0817 - acc: 0.9703\n",
      "Epoch 33/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0818 - acc: 0.9703\n",
      "Epoch 34/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0819 - acc: 0.9705\n",
      "Epoch 35/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0806 - acc: 0.9705\n",
      "Epoch 36/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0812 - acc: 0.9702\n",
      "(?, 30)\n",
      "Epoch 1/36\n",
      "8288/8288 [==============================] - 22s 3ms/step - loss: 0.2088 - acc: 0.9362\n",
      "Epoch 2/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1472 - acc: 0.9607\n",
      "Epoch 3/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1275 - acc: 0.9641\n",
      "Epoch 4/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1141 - acc: 0.9660\n",
      "Epoch 5/36\n",
      "8288/8288 [==============================] - 17s 2ms/step - loss: 0.1065 - acc: 0.9668\n",
      "Epoch 6/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1024 - acc: 0.9669\n",
      "Epoch 7/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0996 - acc: 0.9674\n",
      "Epoch 8/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0982 - acc: 0.9676\n",
      "Epoch 9/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0959 - acc: 0.9678\n",
      "Epoch 10/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0946 - acc: 0.9680\n",
      "Epoch 11/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0927 - acc: 0.9682\n",
      "Epoch 12/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0920 - acc: 0.9684\n",
      "Epoch 13/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0907 - acc: 0.9688\n",
      "Epoch 14/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0899 - acc: 0.9688\n",
      "Epoch 15/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0895 - acc: 0.9689\n",
      "Epoch 16/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0888 - acc: 0.9692\n",
      "Epoch 17/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0886 - acc: 0.9690\n",
      "Epoch 18/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0870 - acc: 0.9693\n",
      "Epoch 19/36\n",
      "8288/8288 [==============================] - 16s 2ms/step - loss: 0.0870 - acc: 0.9690\n",
      "Epoch 20/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0864 - acc: 0.9695\n",
      "Epoch 21/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0861 - acc: 0.9694\n",
      "Epoch 22/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0858 - acc: 0.9695\n",
      "Epoch 23/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0844 - acc: 0.9699\n",
      "Epoch 24/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0845 - acc: 0.9700\n",
      "Epoch 25/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0843 - acc: 0.9696\n",
      "Epoch 26/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0844 - acc: 0.9700\n",
      "Epoch 27/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0840 - acc: 0.9699\n",
      "Epoch 28/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0835 - acc: 0.9698\n",
      "Epoch 29/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0838 - acc: 0.9698\n",
      "Epoch 30/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0830 - acc: 0.9698\n",
      "Epoch 31/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0821 - acc: 0.9702\n",
      "Epoch 32/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0823 - acc: 0.9697\n",
      "Epoch 33/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0818 - acc: 0.9698\n",
      "Epoch 34/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0813 - acc: 0.9702\n",
      "Epoch 35/36\n",
      "8288/8288 [==============================] - 16s 2ms/step - loss: 0.0812 - acc: 0.9702\n",
      "Epoch 36/36\n",
      "8288/8288 [==============================] - 16s 2ms/step - loss: 0.0801 - acc: 0.9705\n",
      "(?, 30)\n",
      "Epoch 1/36\n",
      "8288/8288 [==============================] - 24s 3ms/step - loss: 0.2073 - acc: 0.9366\n",
      "Epoch 2/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1469 - acc: 0.9609\n",
      "Epoch 3/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1252 - acc: 0.9647\n",
      "Epoch 4/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1145 - acc: 0.9661\n",
      "Epoch 5/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1066 - acc: 0.9667\n",
      "Epoch 6/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1024 - acc: 0.9668\n",
      "Epoch 7/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0990 - acc: 0.9675\n",
      "Epoch 8/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0966 - acc: 0.9677\n",
      "Epoch 9/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0948 - acc: 0.9680\n",
      "Epoch 10/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0936 - acc: 0.9682\n",
      "Epoch 11/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0912 - acc: 0.9685\n",
      "Epoch 12/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0906 - acc: 0.9691\n",
      "Epoch 13/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0898 - acc: 0.9685\n",
      "Epoch 14/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0879 - acc: 0.9690\n",
      "Epoch 15/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0872 - acc: 0.9691\n",
      "Epoch 16/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0867 - acc: 0.9695\n",
      "Epoch 17/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0862 - acc: 0.9693\n",
      "Epoch 18/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0864 - acc: 0.9694\n",
      "Epoch 19/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0862 - acc: 0.9693\n",
      "Epoch 20/36\n",
      "8288/8288 [==============================] - 17s 2ms/step - loss: 0.0855 - acc: 0.9696\n",
      "Epoch 21/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0854 - acc: 0.9697\n",
      "Epoch 22/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0840 - acc: 0.9698\n",
      "Epoch 23/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0842 - acc: 0.9699\n",
      "Epoch 24/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0837 - acc: 0.9701\n",
      "Epoch 25/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0832 - acc: 0.9701\n",
      "Epoch 26/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0825 - acc: 0.9699\n",
      "Epoch 27/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0820 - acc: 0.9703\n",
      "Epoch 28/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0820 - acc: 0.9705\n",
      "Epoch 29/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0825 - acc: 0.9702\n",
      "Epoch 30/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0814 - acc: 0.9703\n",
      "Epoch 31/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0813 - acc: 0.9704\n",
      "Epoch 32/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0814 - acc: 0.9698\n",
      "Epoch 33/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0803 - acc: 0.9703\n",
      "Epoch 34/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0807 - acc: 0.9704\n",
      "Epoch 35/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0801 - acc: 0.9704\n",
      "Epoch 36/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0803 - acc: 0.9705\n",
      "(?, 30)\n",
      "Epoch 1/36\n",
      "8288/8288 [==============================] - 24s 3ms/step - loss: 0.2043 - acc: 0.9384\n",
      "Epoch 2/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1459 - acc: 0.9611\n",
      "Epoch 3/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1262 - acc: 0.9644\n",
      "Epoch 4/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1146 - acc: 0.9660\n",
      "Epoch 5/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1091 - acc: 0.9664\n",
      "Epoch 6/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1041 - acc: 0.9672\n",
      "Epoch 7/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1005 - acc: 0.9675\n",
      "Epoch 8/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0990 - acc: 0.9678\n",
      "Epoch 9/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0961 - acc: 0.9679\n",
      "Epoch 10/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0949 - acc: 0.9684\n",
      "Epoch 11/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0939 - acc: 0.9688\n",
      "Epoch 12/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0924 - acc: 0.9686\n",
      "Epoch 13/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0913 - acc: 0.9688\n",
      "Epoch 14/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0900 - acc: 0.9691\n",
      "Epoch 15/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0896 - acc: 0.9689\n",
      "Epoch 16/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0888 - acc: 0.9692\n",
      "Epoch 17/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0883 - acc: 0.9691\n",
      "Epoch 18/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0875 - acc: 0.9692\n",
      "Epoch 19/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0875 - acc: 0.9691\n",
      "Epoch 20/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0872 - acc: 0.9693\n",
      "Epoch 21/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0869 - acc: 0.9694\n",
      "Epoch 22/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0860 - acc: 0.9700\n",
      "Epoch 23/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0856 - acc: 0.9695\n",
      "Epoch 24/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0847 - acc: 0.9697\n",
      "Epoch 25/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0845 - acc: 0.9697\n",
      "Epoch 26/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0837 - acc: 0.9699\n",
      "Epoch 27/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0833 - acc: 0.9698\n",
      "Epoch 28/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0837 - acc: 0.9701\n",
      "Epoch 29/36\n",
      "8288/8288 [==============================] - 16s 2ms/step - loss: 0.0835 - acc: 0.9697\n",
      "Epoch 30/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0825 - acc: 0.9701\n",
      "Epoch 31/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0822 - acc: 0.9700\n",
      "Epoch 32/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0825 - acc: 0.9702\n",
      "Epoch 33/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0815 - acc: 0.9705\n",
      "Epoch 34/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0820 - acc: 0.9706\n",
      "Epoch 35/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0814 - acc: 0.9702\n",
      "Epoch 36/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0811 - acc: 0.9704\n",
      "(?, 30)\n",
      "Epoch 1/36\n",
      "8288/8288 [==============================] - 24s 3ms/step - loss: 0.2079 - acc: 0.9364\n",
      "Epoch 2/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1446 - acc: 0.9615\n",
      "Epoch 3/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1245 - acc: 0.9648\n",
      "Epoch 4/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1134 - acc: 0.9660\n",
      "Epoch 5/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1079 - acc: 0.9667\n",
      "Epoch 6/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.1037 - acc: 0.9670\n",
      "Epoch 7/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.1012 - acc: 0.9676\n",
      "Epoch 8/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0979 - acc: 0.9679\n",
      "Epoch 9/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0960 - acc: 0.9681\n",
      "Epoch 10/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0948 - acc: 0.9684\n",
      "Epoch 11/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0926 - acc: 0.9685\n",
      "Epoch 12/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0922 - acc: 0.9685\n",
      "Epoch 13/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0909 - acc: 0.9687\n",
      "Epoch 14/36\n",
      "8288/8288 [==============================] - 14s 2ms/step - loss: 0.0899 - acc: 0.9688\n",
      "Epoch 15/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0896 - acc: 0.9692\n",
      "Epoch 16/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0887 - acc: 0.9691\n",
      "Epoch 17/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0884 - acc: 0.9691\n",
      "Epoch 18/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0884 - acc: 0.9692\n",
      "Epoch 19/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0873 - acc: 0.9696\n",
      "Epoch 20/36\n",
      "8288/8288 [==============================] - 13s 2ms/step - loss: 0.0868 - acc: 0.9692\n",
      "Epoch 21/36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8288/8288 [==============================] - 13s 2ms/step - loss: 0.0855 - acc: 0.9698\n",
      "Epoch 22/36\n",
      "8288/8288 [==============================] - 10s 1ms/step - loss: 0.0850 - acc: 0.9695\n",
      "Epoch 23/36\n",
      "8288/8288 [==============================] - 9s 1ms/step - loss: 0.0846 - acc: 0.9700\n",
      "Epoch 24/36\n",
      "8288/8288 [==============================] - 12s 1ms/step - loss: 0.0846 - acc: 0.9699\n",
      "Epoch 25/36\n",
      "8288/8288 [==============================] - 16s 2ms/step - loss: 0.0839 - acc: 0.9698\n",
      "Epoch 26/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0839 - acc: 0.9700\n",
      "Epoch 27/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0833 - acc: 0.9699\n",
      "Epoch 28/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0829 - acc: 0.9701\n",
      "Epoch 29/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0833 - acc: 0.9698\n",
      "Epoch 30/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0833 - acc: 0.9700\n",
      "Epoch 31/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0830 - acc: 0.9703\n",
      "Epoch 32/36\n",
      "8288/8288 [==============================] - 15s 2ms/step - loss: 0.0824 - acc: 0.9702\n",
      "Epoch 33/36\n",
      "8288/8288 [==============================] - 13s 2ms/step - loss: 0.0819 - acc: 0.9704\n",
      "Epoch 34/36\n",
      "8288/8288 [==============================] - 13s 2ms/step - loss: 0.0824 - acc: 0.9701\n",
      "Epoch 35/36\n",
      "8288/8288 [==============================] - 13s 2ms/step - loss: 0.0813 - acc: 0.9705\n",
      "Epoch 36/36\n",
      "8288/8288 [==============================] - 13s 2ms/step - loss: 0.0816 - acc: 0.9705\n"
     ]
    }
   ],
   "source": [
    "first_model_results = []\n",
    "for i in range(5):\n",
    "    log_filepath = './tmp/log' \n",
    "    callback = [keras.callbacks.TensorBoard(log_dir=log_filepath, write_images=1, histogram_freq=1)] \n",
    " \n",
    "    model = get_hi_text_cnn_model()\n",
    "    model.fit(X_train, y_train, batch_size=32, shuffle=True, epochs=36,\n",
    "             callbacks=callback, validation_data=(X_valid, y_valid))  # batch_size: 16, epochs = 15\n",
    "    first_model_results.append(model.predict(X_dev, batch_size=1024))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2364, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(first_model_results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = np.average(first_model_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('../data/output/submission/ck2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/output/hi_text_cnn.txt', pred4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
