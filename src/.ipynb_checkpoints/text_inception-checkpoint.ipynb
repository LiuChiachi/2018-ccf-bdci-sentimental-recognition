{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/liujiaqi/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://github.com/312shan/Subject-and-Sentiment-Analysis\n",
    "\"\"\"\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "from capsule import *\n",
    "import jieba\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, SpatialDropout2D, Activation, Embedding, Flatten, Conv2D, MaxPool2D\n",
    " \n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Reshape, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from keras.layers import BatchNormalization\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "test_size = 0#.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.374 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22452\n",
      "Found 635793 word vectors.\n"
     ]
    }
   ],
   "source": [
    "if test_size == 0:\n",
    "    stop_words = load_stop_words()\n",
    "    seqs, seqs_dev, word2index, y_train = raw_file2matrix(train_file, test_file, stop_words)\n",
    "    embeddings_index = load_embeddings_index()\n",
    "    embedding_matrix = get_embedding_matrix(word2index, embeddings_index)  # word-index-embedding是它们之间的链接关系\n",
    "    \n",
    "    X_train = np.loadtxt('../data/output/matrixes/X_train_2')\n",
    "    y_train = np.loadtxt('../data/output/matrixes/y_train_2')\n",
    "    X_test = np.loadtxt('../data/output/matrixes/X_test_2')\n",
    "    # X_trains, y_trains = generate_shuffle_array(X_train, y_train)\n",
    "    # drop_array(X_trains)\n",
    "else:\n",
    "    stop_words = load_stop_words()\n",
    "    seqs_train, seqs_valid, seqs_dev, word2index, y_train, y_valid, train_id_label_dict, valid_label = raw_file_2_matrix(train_file, test_file, stop_words, test_size=test_size)\n",
    "\n",
    "    embeddings_index = load_embeddings_index()\n",
    "    embedding_matrix = get_embedding_matrix(word2index, embeddings_index)  # word-index-embedding是它们之间的链接关系\n",
    "    X_train, X_valid, X_test = get_padding_data(seqs_train, seqs_valid, seqs_dev)  # seqs needs to be a list of a list.把列表变成矩阵，列数是embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_inception():\n",
    "    maxlen = 100\n",
    "\n",
    "    num_filter = 64\n",
    "    drop = 0.6\n",
    "    inputs = Input(shape=(maxlen,))\n",
    "    embed_layer = Embedding(len(word2index)+1, EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "                                input_length=maxlen, trainable=True)(inputs)\n",
    "    embed_layer = SpatialDropout1D(drop)(embed_layer)\n",
    "    # 1\n",
    "    conv1 = Conv1D(filters=num_filter, kernel_size=1, strides=1, padding='same', activation=None)(embed_layer)\n",
    "    conv1 = Dropout(drop)(conv1)\n",
    "    # 2\n",
    "    conv1_1 = Conv1D(filters=num_filter, kernel_size=1, strides=1, padding='same', activation=None)(embed_layer)\n",
    "    conv1_bn = BatchNormalization()(conv1_1)\n",
    "    conv1_relu = Activation('relu')(conv1_bn)\n",
    "    conv1_relu = Dropout(drop)(conv1_relu)\n",
    "    conv1_3 = Conv1D(filters=num_filter, kernel_size=3, strides=1, padding='same', activation=None)(conv1_relu)\n",
    "    # conv_3 = Dropout(drop)(conv1_3)\n",
    "    # 3\n",
    "    conv3_1 = Conv1D(filters=num_filter, kernel_size=3, strides=1, padding='same', activation=None)(embed_layer)\n",
    "    conv3_bn = BatchNormalization()(conv3_1)\n",
    "    conv3_relu = Activation('relu')(conv3_bn)\n",
    "    conv3_relu = Dropout(drop)(conv3_relu)\n",
    "    conv3_5 = Conv1D(filters=num_filter, kernel_size=5, strides=1, padding='same', activation=None)(conv3_relu)\n",
    "    # conv3_5 = Dropout(drop)(conv3_5)\n",
    "    # 4\n",
    "    conv3 = Conv1D(filters=num_filter, kernel_size=3, strides=1, padding='same', activation=None)(embed_layer)\n",
    "    # conv3 = Dropout(drop)(conv3)\n",
    "    # concat\n",
    "    conv_concat = Concatenate(axis=1)([conv1, conv1_3, conv3_5, conv3])\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(conv_concat)\n",
    "    max_pool = GlobalMaxPooling1D()(conv_concat)\n",
    "    conv_concat  = Concatenate()([avg_pool, max_pool])\n",
    "    \n",
    "    # conv_flatten = Flatten()(conv_concat)\n",
    "    conv_drop = Dropout(drop)(conv_concat)\n",
    "    conv_bn = BatchNormalization()(conv_drop)\n",
    "    conv_relu = Activation('relu')(conv_bn)\n",
    "    conv_dropout = Dropout(drop)(conv_relu)\n",
    "    outputs = Dense(30, activation='sigmoid')(conv_dropout)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    learning_rate = 0.0001\n",
    "    adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0)\n",
    "    sgd = SGD(lr=learning_rate, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    rmsprop = RMSprop(lr=learning_rate, rho=0.9, epsilon=None, decay=0.0)\n",
    "    \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1_score])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9587 samples, validate on 1066 samples\n",
      "Epoch 1/60\n",
      "9587/9587 [==============================] - 72s 7ms/step - loss: 0.2181 - f1_score: 0.0408 - val_loss: 0.3605 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.00000, saving model to ../models/weights/text_inception-01-0.0000-0.3605.hdf5\n",
      "Epoch 2/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1629 - f1_score: 0.0374 - val_loss: 0.3187 - val_f1_score: 0.1021\n",
      "\n",
      "Epoch 00002: val_f1_score improved from 0.00000 to 0.10205, saving model to ../models/weights/text_inception-02-0.1021-0.3187.hdf5\n",
      "Epoch 3/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1547 - f1_score: 0.0804 - val_loss: 0.2958 - val_f1_score: 0.1400\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.10205 to 0.13999, saving model to ../models/weights/text_inception-03-0.1400-0.2958.hdf5\n",
      "Epoch 4/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1504 - f1_score: 0.1107 - val_loss: 0.2292 - val_f1_score: 0.1498\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.13999 to 0.14978, saving model to ../models/weights/text_inception-04-0.1498-0.2292.hdf5\n",
      "Epoch 5/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1461 - f1_score: 0.1372 - val_loss: 0.2246 - val_f1_score: 0.2455\n",
      "\n",
      "Epoch 00005: val_f1_score improved from 0.14978 to 0.24553, saving model to ../models/weights/text_inception-05-0.2455-0.2246.hdf5\n",
      "Epoch 6/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1417 - f1_score: 0.1686 - val_loss: 0.2077 - val_f1_score: 0.3121\n",
      "\n",
      "Epoch 00006: val_f1_score improved from 0.24553 to 0.31214, saving model to ../models/weights/text_inception-06-0.3121-0.2077.hdf5\n",
      "Epoch 7/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1374 - f1_score: 0.2050 - val_loss: 0.1618 - val_f1_score: 0.3342\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.31214 to 0.33418, saving model to ../models/weights/text_inception-07-0.3342-0.1618.hdf5\n",
      "Epoch 8/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1346 - f1_score: 0.2362 - val_loss: 0.1375 - val_f1_score: 0.3882\n",
      "\n",
      "Epoch 00008: val_f1_score improved from 0.33418 to 0.38817, saving model to ../models/weights/text_inception-08-0.3882-0.1375.hdf5\n",
      "Epoch 9/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1314 - f1_score: 0.2662 - val_loss: 0.1260 - val_f1_score: 0.4425\n",
      "\n",
      "Epoch 00009: val_f1_score improved from 0.38817 to 0.44246, saving model to ../models/weights/text_inception-09-0.4425-0.1260.hdf5\n",
      "Epoch 10/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1281 - f1_score: 0.2800 - val_loss: 0.1122 - val_f1_score: 0.4671\n",
      "\n",
      "Epoch 00010: val_f1_score improved from 0.44246 to 0.46714, saving model to ../models/weights/text_inception-10-0.4671-0.1122.hdf5\n",
      "Epoch 11/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1264 - f1_score: 0.3010 - val_loss: 0.1082 - val_f1_score: 0.4463\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.46714\n",
      "Epoch 12/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1240 - f1_score: 0.3040 - val_loss: 0.1078 - val_f1_score: 0.4487\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.46714\n",
      "Epoch 13/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1225 - f1_score: 0.3128 - val_loss: 0.1024 - val_f1_score: 0.4613\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.46714\n",
      "Epoch 14/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1211 - f1_score: 0.3218 - val_loss: 0.0995 - val_f1_score: 0.4638\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.46714\n",
      "Epoch 15/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1198 - f1_score: 0.3333 - val_loss: 0.0953 - val_f1_score: 0.4784\n",
      "\n",
      "Epoch 00015: val_f1_score improved from 0.46714 to 0.47840, saving model to ../models/weights/text_inception-15-0.4784-0.0953.hdf5\n",
      "Epoch 16/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1187 - f1_score: 0.3297 - val_loss: 0.0973 - val_f1_score: 0.4692\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.47840\n",
      "Epoch 17/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1177 - f1_score: 0.3372 - val_loss: 0.0958 - val_f1_score: 0.4536\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.47840\n",
      "Epoch 18/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1167 - f1_score: 0.3419 - val_loss: 0.0971 - val_f1_score: 0.4794\n",
      "\n",
      "Epoch 00018: val_f1_score improved from 0.47840 to 0.47938, saving model to ../models/weights/text_inception-18-0.4794-0.0971.hdf5\n",
      "Epoch 19/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1157 - f1_score: 0.3432 - val_loss: 0.0934 - val_f1_score: 0.4738\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.47938\n",
      "Epoch 20/60\n",
      "9587/9587 [==============================] - 67s 7ms/step - loss: 0.1150 - f1_score: 0.3457 - val_loss: 0.0929 - val_f1_score: 0.4826\n",
      "\n",
      "Epoch 00020: val_f1_score improved from 0.47938 to 0.48257, saving model to ../models/weights/text_inception-20-0.4826-0.0929.hdf5\n",
      "Epoch 21/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1144 - f1_score: 0.3554 - val_loss: 0.0924 - val_f1_score: 0.4677\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.48257\n",
      "Epoch 22/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1126 - f1_score: 0.3629 - val_loss: 0.0897 - val_f1_score: 0.4908\n",
      "\n",
      "Epoch 00022: val_f1_score improved from 0.48257 to 0.49076, saving model to ../models/weights/text_inception-22-0.4908-0.0897.hdf5\n",
      "Epoch 23/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1121 - f1_score: 0.3601 - val_loss: 0.0898 - val_f1_score: 0.5015\n",
      "\n",
      "Epoch 00023: val_f1_score improved from 0.49076 to 0.50153, saving model to ../models/weights/text_inception-23-0.5015-0.0898.hdf5\n",
      "Epoch 24/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1118 - f1_score: 0.3628 - val_loss: 0.0909 - val_f1_score: 0.4781\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.50153\n",
      "Epoch 25/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1108 - f1_score: 0.3689 - val_loss: 0.0898 - val_f1_score: 0.4860\n",
      "\n",
      "Epoch 00025: val_f1_score did not improve from 0.50153\n",
      "Epoch 26/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1094 - f1_score: 0.3745 - val_loss: 0.0880 - val_f1_score: 0.4734\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.50153\n",
      "Epoch 27/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1094 - f1_score: 0.3786 - val_loss: 0.0862 - val_f1_score: 0.4932\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.50153\n",
      "Epoch 28/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1092 - f1_score: 0.3722 - val_loss: 0.0850 - val_f1_score: 0.4896\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.50153\n",
      "Epoch 29/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1082 - f1_score: 0.3781 - val_loss: 0.0866 - val_f1_score: 0.4872\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.50153\n",
      "Epoch 30/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1077 - f1_score: 0.3931 - val_loss: 0.0860 - val_f1_score: 0.4574\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.50153\n",
      "Epoch 31/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1069 - f1_score: 0.3882 - val_loss: 0.0865 - val_f1_score: 0.4713\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.50153\n",
      "Epoch 32/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1065 - f1_score: 0.3880 - val_loss: 0.0837 - val_f1_score: 0.4680\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.50153\n",
      "Epoch 33/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1065 - f1_score: 0.3905 - val_loss: 0.0857 - val_f1_score: 0.4626\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.50153\n",
      "Epoch 34/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1057 - f1_score: 0.3898 - val_loss: 0.0828 - val_f1_score: 0.4629\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.50153\n",
      "Epoch 35/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1053 - f1_score: 0.3987 - val_loss: 0.0870 - val_f1_score: 0.3883\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.50153\n",
      "Epoch 36/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1044 - f1_score: 0.3963 - val_loss: 0.0812 - val_f1_score: 0.4700\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.50153\n",
      "Epoch 37/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1041 - f1_score: 0.4010 - val_loss: 0.0840 - val_f1_score: 0.4422\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.50153\n",
      "Epoch 38/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1037 - f1_score: 0.4040 - val_loss: 0.0857 - val_f1_score: 0.3501\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.50153\n",
      "Epoch 39/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1032 - f1_score: 0.4090 - val_loss: 0.0841 - val_f1_score: 0.3806\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.50153\n",
      "Epoch 40/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1033 - f1_score: 0.4038 - val_loss: 0.0844 - val_f1_score: 0.3556\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.50153\n",
      "Epoch 41/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1022 - f1_score: 0.4038 - val_loss: 0.0863 - val_f1_score: 0.3395\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.50153\n",
      "Epoch 42/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1028 - f1_score: 0.4093 - val_loss: 0.0850 - val_f1_score: 0.3114\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.50153\n",
      "Epoch 43/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1018 - f1_score: 0.4092 - val_loss: 0.0875 - val_f1_score: 0.2619\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.50153\n",
      "Epoch 44/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1017 - f1_score: 0.4059 - val_loss: 0.0832 - val_f1_score: 0.3326\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.50153\n",
      "Epoch 45/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1014 - f1_score: 0.4124 - val_loss: 0.0840 - val_f1_score: 0.3040\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.50153\n",
      "Epoch 46/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1008 - f1_score: 0.4104 - val_loss: 0.0858 - val_f1_score: 0.2478\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.50153\n",
      "Epoch 47/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1007 - f1_score: 0.4103 - val_loss: 0.0849 - val_f1_score: 0.3061\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.50153\n",
      "Epoch 48/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1000 - f1_score: 0.4193 - val_loss: 0.0872 - val_f1_score: 0.2325\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.50153\n",
      "Epoch 49/60\n",
      "9587/9587 [==============================] - 67s 7ms/step - loss: 0.1000 - f1_score: 0.4198 - val_loss: 0.0869 - val_f1_score: 0.2010\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.50153\n",
      "Epoch 50/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0997 - f1_score: 0.4179 - val_loss: 0.0878 - val_f1_score: 0.2299\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.50153\n",
      "Epoch 51/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0994 - f1_score: 0.4163 - val_loss: 0.0877 - val_f1_score: 0.2283\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.50153\n",
      "Epoch 52/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0992 - f1_score: 0.4218 - val_loss: 0.0882 - val_f1_score: 0.1790\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.50153\n",
      "Epoch 53/60\n",
      "9587/9587 [==============================] - 67s 7ms/step - loss: 0.0988 - f1_score: 0.4190 - val_loss: 0.0879 - val_f1_score: 0.1683\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.50153\n",
      "Epoch 54/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0989 - f1_score: 0.4161 - val_loss: 0.0885 - val_f1_score: 0.1818\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.50153\n",
      "Epoch 55/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0975 - f1_score: 0.4286 - val_loss: 0.0897 - val_f1_score: 0.1652\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.50153\n",
      "Epoch 56/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0975 - f1_score: 0.4285 - val_loss: 0.0886 - val_f1_score: 0.1660\n",
      "\n",
      "Epoch 00056: val_f1_score did not improve from 0.50153\n",
      "Epoch 57/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0981 - f1_score: 0.4166 - val_loss: 0.0894 - val_f1_score: 0.1722\n",
      "\n",
      "Epoch 00057: val_f1_score did not improve from 0.50153\n",
      "Epoch 58/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0979 - f1_score: 0.4305 - val_loss: 0.0904 - val_f1_score: 0.1486\n",
      "\n",
      "Epoch 00058: val_f1_score did not improve from 0.50153\n",
      "Epoch 59/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0975 - f1_score: 0.4326 - val_loss: 0.0928 - val_f1_score: 0.1196\n",
      "\n",
      "Epoch 00059: val_f1_score did not improve from 0.50153\n",
      "Epoch 60/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0972 - f1_score: 0.4279 - val_loss: 0.0898 - val_f1_score: 0.1471\n",
      "\n",
      "Epoch 00060: val_f1_score did not improve from 0.50153\n",
      "Train on 9587 samples, validate on 1066 samples\n",
      "Epoch 1/60\n",
      "9587/9587 [==============================] - 73s 8ms/step - loss: 0.2190 - f1_score: 0.0485 - val_loss: 0.3904 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.00000, saving model to ../models/weights/text_inception-01-0.0000-0.3904.hdf5\n",
      "Epoch 2/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1628 - f1_score: 0.0473 - val_loss: 0.3283 - val_f1_score: 0.1113\n",
      "\n",
      "Epoch 00002: val_f1_score improved from 0.00000 to 0.11133, saving model to ../models/weights/text_inception-02-0.1113-0.3283.hdf5\n",
      "Epoch 3/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1556 - f1_score: 0.0880 - val_loss: 0.2980 - val_f1_score: 0.1215\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.11133 to 0.12153, saving model to ../models/weights/text_inception-03-0.1215-0.2980.hdf5\n",
      "Epoch 4/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1505 - f1_score: 0.1255 - val_loss: 0.2740 - val_f1_score: 0.1532\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.12153 to 0.15324, saving model to ../models/weights/text_inception-04-0.1532-0.2740.hdf5\n",
      "Epoch 5/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1456 - f1_score: 0.1380 - val_loss: 0.2103 - val_f1_score: 0.1735\n",
      "\n",
      "Epoch 00005: val_f1_score improved from 0.15324 to 0.17352, saving model to ../models/weights/text_inception-05-0.1735-0.2103.hdf5\n",
      "Epoch 6/60\n",
      "9587/9587 [==============================] - 59s 6ms/step - loss: 0.1408 - f1_score: 0.1789 - val_loss: 0.1713 - val_f1_score: 0.2740\n",
      "\n",
      "Epoch 00006: val_f1_score improved from 0.17352 to 0.27398, saving model to ../models/weights/text_inception-06-0.2740-0.1713.hdf5\n",
      "Epoch 7/60\n",
      "9587/9587 [==============================] - 63s 7ms/step - loss: 0.1356 - f1_score: 0.2327 - val_loss: 0.1508 - val_f1_score: 0.3645\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.27398 to 0.36452, saving model to ../models/weights/text_inception-07-0.3645-0.1508.hdf5\n",
      "Epoch 8/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1317 - f1_score: 0.2690 - val_loss: 0.1284 - val_f1_score: 0.4213\n",
      "\n",
      "Epoch 00008: val_f1_score improved from 0.36452 to 0.42133, saving model to ../models/weights/text_inception-08-0.4213-0.1284.hdf5\n",
      "Epoch 9/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1288 - f1_score: 0.2862 - val_loss: 0.1182 - val_f1_score: 0.4342\n",
      "\n",
      "Epoch 00009: val_f1_score improved from 0.42133 to 0.43418, saving model to ../models/weights/text_inception-09-0.4342-0.1182.hdf5\n",
      "Epoch 10/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1268 - f1_score: 0.2987 - val_loss: 0.1119 - val_f1_score: 0.4466\n",
      "\n",
      "Epoch 00010: val_f1_score improved from 0.43418 to 0.44659, saving model to ../models/weights/text_inception-10-0.4466-0.1119.hdf5\n",
      "Epoch 11/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1239 - f1_score: 0.3090 - val_loss: 0.1044 - val_f1_score: 0.4671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_f1_score improved from 0.44659 to 0.46707, saving model to ../models/weights/text_inception-11-0.4671-0.1044.hdf5\n",
      "Epoch 12/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1227 - f1_score: 0.3202 - val_loss: 0.1059 - val_f1_score: 0.4488\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.46707\n",
      "Epoch 13/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1210 - f1_score: 0.3158 - val_loss: 0.1029 - val_f1_score: 0.4507\n",
      "\n",
      "Epoch 00013: val_f1_score did not improve from 0.46707\n",
      "Epoch 14/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1200 - f1_score: 0.3312 - val_loss: 0.0991 - val_f1_score: 0.4542\n",
      "\n",
      "Epoch 00014: val_f1_score did not improve from 0.46707\n",
      "Epoch 15/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1186 - f1_score: 0.3284 - val_loss: 0.0974 - val_f1_score: 0.4716\n",
      "\n",
      "Epoch 00015: val_f1_score improved from 0.46707 to 0.47159, saving model to ../models/weights/text_inception-15-0.4716-0.0974.hdf5\n",
      "Epoch 16/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1181 - f1_score: 0.3381 - val_loss: 0.0973 - val_f1_score: 0.4807\n",
      "\n",
      "Epoch 00016: val_f1_score improved from 0.47159 to 0.48068, saving model to ../models/weights/text_inception-16-0.4807-0.0973.hdf5\n",
      "Epoch 17/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1169 - f1_score: 0.3374 - val_loss: 0.0979 - val_f1_score: 0.4636\n",
      "\n",
      "Epoch 00017: val_f1_score did not improve from 0.48068\n",
      "Epoch 18/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1164 - f1_score: 0.3395 - val_loss: 0.0986 - val_f1_score: 0.4866\n",
      "\n",
      "Epoch 00018: val_f1_score improved from 0.48068 to 0.48658, saving model to ../models/weights/text_inception-18-0.4866-0.0986.hdf5\n",
      "Epoch 19/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1156 - f1_score: 0.3506 - val_loss: 0.0951 - val_f1_score: 0.4819\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.48658\n",
      "Epoch 20/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1142 - f1_score: 0.3629 - val_loss: 0.0932 - val_f1_score: 0.4677\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.48658\n",
      "Epoch 21/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1131 - f1_score: 0.3581 - val_loss: 0.0946 - val_f1_score: 0.4660\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.48658\n",
      "Epoch 22/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1128 - f1_score: 0.3592 - val_loss: 0.0920 - val_f1_score: 0.4708\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.48658\n",
      "Epoch 23/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1122 - f1_score: 0.3577 - val_loss: 0.0911 - val_f1_score: 0.4876\n",
      "\n",
      "Epoch 00023: val_f1_score improved from 0.48658 to 0.48764, saving model to ../models/weights/text_inception-23-0.4876-0.0911.hdf5\n",
      "Epoch 24/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1111 - f1_score: 0.3697 - val_loss: 0.0916 - val_f1_score: 0.4592\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.48764\n",
      "Epoch 25/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1104 - f1_score: 0.3718 - val_loss: 0.0879 - val_f1_score: 0.4898\n",
      "\n",
      "Epoch 00025: val_f1_score improved from 0.48764 to 0.48979, saving model to ../models/weights/text_inception-25-0.4898-0.0879.hdf5\n",
      "Epoch 26/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1100 - f1_score: 0.3668 - val_loss: 0.0899 - val_f1_score: 0.4779\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.48979\n",
      "Epoch 27/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1091 - f1_score: 0.3835 - val_loss: 0.0903 - val_f1_score: 0.4465\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.48979\n",
      "Epoch 28/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1079 - f1_score: 0.3902 - val_loss: 0.0887 - val_f1_score: 0.4685\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.48979\n",
      "Epoch 29/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1081 - f1_score: 0.3814 - val_loss: 0.0851 - val_f1_score: 0.4794\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.48979\n",
      "Epoch 30/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1076 - f1_score: 0.3936 - val_loss: 0.0871 - val_f1_score: 0.4614\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.48979\n",
      "Epoch 31/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1056 - f1_score: 0.3982 - val_loss: 0.0857 - val_f1_score: 0.4485\n",
      "\n",
      "Epoch 00031: val_f1_score did not improve from 0.48979\n",
      "Epoch 32/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1064 - f1_score: 0.3951 - val_loss: 0.0868 - val_f1_score: 0.4422\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.48979\n",
      "Epoch 33/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1060 - f1_score: 0.3930 - val_loss: 0.0867 - val_f1_score: 0.4250\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.48979\n",
      "Epoch 34/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1053 - f1_score: 0.4000 - val_loss: 0.0859 - val_f1_score: 0.4264\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.48979\n",
      "Epoch 35/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1043 - f1_score: 0.4066 - val_loss: 0.0849 - val_f1_score: 0.4281\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.48979\n",
      "Epoch 36/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1038 - f1_score: 0.4037 - val_loss: 0.0847 - val_f1_score: 0.3926\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.48979\n",
      "Epoch 37/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1041 - f1_score: 0.4004 - val_loss: 0.0853 - val_f1_score: 0.3851\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.48979\n",
      "Epoch 38/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1037 - f1_score: 0.4096 - val_loss: 0.0879 - val_f1_score: 0.3539\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.48979\n",
      "Epoch 39/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1027 - f1_score: 0.4080 - val_loss: 0.0861 - val_f1_score: 0.3427\n",
      "\n",
      "Epoch 00039: val_f1_score did not improve from 0.48979\n",
      "Epoch 40/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1023 - f1_score: 0.4107 - val_loss: 0.0831 - val_f1_score: 0.3639\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.48979\n",
      "Epoch 41/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1027 - f1_score: 0.4116 - val_loss: 0.0830 - val_f1_score: 0.3393\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.48979\n",
      "Epoch 42/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1016 - f1_score: 0.4182 - val_loss: 0.0890 - val_f1_score: 0.2604\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.48979\n",
      "Epoch 43/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1012 - f1_score: 0.4146 - val_loss: 0.0843 - val_f1_score: 0.3356\n",
      "\n",
      "Epoch 00043: val_f1_score did not improve from 0.48979\n",
      "Epoch 44/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1009 - f1_score: 0.4191 - val_loss: 0.0868 - val_f1_score: 0.3046\n",
      "\n",
      "Epoch 00044: val_f1_score did not improve from 0.48979\n",
      "Epoch 45/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1010 - f1_score: 0.4209 - val_loss: 0.0872 - val_f1_score: 0.2422\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.48979\n",
      "Epoch 46/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.0998 - f1_score: 0.4206 - val_loss: 0.0835 - val_f1_score: 0.3082\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.48979\n",
      "Epoch 47/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.0994 - f1_score: 0.4224 - val_loss: 0.0852 - val_f1_score: 0.2718\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.48979\n",
      "Epoch 48/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.0999 - f1_score: 0.4187 - val_loss: 0.0905 - val_f1_score: 0.1967\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.48979\n",
      "Epoch 49/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.0997 - f1_score: 0.4166 - val_loss: 0.0884 - val_f1_score: 0.1968\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.48979\n",
      "Epoch 50/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1000 - f1_score: 0.4176 - val_loss: 0.0893 - val_f1_score: 0.1835\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.48979\n",
      "Epoch 51/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0989 - f1_score: 0.4183 - val_loss: 0.0888 - val_f1_score: 0.1921\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.48979\n",
      "Epoch 52/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.0985 - f1_score: 0.4270 - val_loss: 0.0882 - val_f1_score: 0.2208\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.48979\n",
      "Epoch 53/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.0989 - f1_score: 0.4257 - val_loss: 0.0903 - val_f1_score: 0.1711\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.48979\n",
      "Epoch 54/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.0982 - f1_score: 0.4289 - val_loss: 0.0880 - val_f1_score: 0.1813\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.48979\n",
      "Epoch 55/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0980 - f1_score: 0.4230 - val_loss: 0.0877 - val_f1_score: 0.1833\n",
      "\n",
      "Epoch 00055: val_f1_score did not improve from 0.48979\n",
      "Epoch 56/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0980 - f1_score: 0.4247 - val_loss: 0.0928 - val_f1_score: 0.1420\n",
      "\n",
      "Epoch 00056: val_f1_score did not improve from 0.48979\n",
      "Epoch 57/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0968 - f1_score: 0.4269 - val_loss: 0.0913 - val_f1_score: 0.1647\n",
      "\n",
      "Epoch 00057: val_f1_score did not improve from 0.48979\n",
      "Epoch 58/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.0975 - f1_score: 0.4250 - val_loss: 0.0868 - val_f1_score: 0.1842\n",
      "\n",
      "Epoch 00058: val_f1_score did not improve from 0.48979\n",
      "Epoch 59/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.0975 - f1_score: 0.4300 - val_loss: 0.0933 - val_f1_score: 0.1396\n",
      "\n",
      "Epoch 00059: val_f1_score did not improve from 0.48979\n",
      "Epoch 60/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.0971 - f1_score: 0.4247 - val_loss: 0.0917 - val_f1_score: 0.1397\n",
      "\n",
      "Epoch 00060: val_f1_score did not improve from 0.48979\n",
      "Train on 9587 samples, validate on 1066 samples\n",
      "Epoch 1/60\n",
      "9587/9587 [==============================] - 73s 8ms/step - loss: 0.2156 - f1_score: 0.0429 - val_loss: 0.3203 - val_f1_score: 0.0086\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.00863, saving model to ../models/weights/text_inception-01-0.0086-0.3203.hdf5\n",
      "Epoch 2/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1625 - f1_score: 0.0530 - val_loss: 0.2933 - val_f1_score: 0.1312\n",
      "\n",
      "Epoch 00002: val_f1_score improved from 0.00863 to 0.13122, saving model to ../models/weights/text_inception-02-0.1312-0.2933.hdf5\n",
      "Epoch 3/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1549 - f1_score: 0.0941 - val_loss: 0.2782 - val_f1_score: 0.1298\n",
      "\n",
      "Epoch 00003: val_f1_score did not improve from 0.13122\n",
      "Epoch 4/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1496 - f1_score: 0.1305 - val_loss: 0.2387 - val_f1_score: 0.1323\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.13122 to 0.13235, saving model to ../models/weights/text_inception-04-0.1323-0.2387.hdf5\n",
      "Epoch 5/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1450 - f1_score: 0.1407 - val_loss: 0.2040 - val_f1_score: 0.2612\n",
      "\n",
      "Epoch 00005: val_f1_score improved from 0.13235 to 0.26123, saving model to ../models/weights/text_inception-05-0.2612-0.2040.hdf5\n",
      "Epoch 6/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1404 - f1_score: 0.1767 - val_loss: 0.1791 - val_f1_score: 0.2363\n",
      "\n",
      "Epoch 00006: val_f1_score did not improve from 0.26123\n",
      "Epoch 7/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1363 - f1_score: 0.2169 - val_loss: 0.1465 - val_f1_score: 0.3433\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.26123 to 0.34328, saving model to ../models/weights/text_inception-07-0.3433-0.1465.hdf5\n",
      "Epoch 8/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1327 - f1_score: 0.2425 - val_loss: 0.1251 - val_f1_score: 0.4011\n",
      "\n",
      "Epoch 00008: val_f1_score improved from 0.34328 to 0.40114, saving model to ../models/weights/text_inception-08-0.4011-0.1251.hdf5\n",
      "Epoch 9/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1293 - f1_score: 0.2819 - val_loss: 0.1153 - val_f1_score: 0.4573\n",
      "\n",
      "Epoch 00009: val_f1_score improved from 0.40114 to 0.45729, saving model to ../models/weights/text_inception-09-0.4573-0.1153.hdf5\n",
      "Epoch 10/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1267 - f1_score: 0.2945 - val_loss: 0.1171 - val_f1_score: 0.4576\n",
      "\n",
      "Epoch 00010: val_f1_score improved from 0.45729 to 0.45765, saving model to ../models/weights/text_inception-10-0.4576-0.1171.hdf5\n",
      "Epoch 11/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1247 - f1_score: 0.3018 - val_loss: 0.1046 - val_f1_score: 0.4437\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.45765\n",
      "Epoch 12/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1225 - f1_score: 0.3091 - val_loss: 0.1043 - val_f1_score: 0.4402\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.45765\n",
      "Epoch 13/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1214 - f1_score: 0.3200 - val_loss: 0.1018 - val_f1_score: 0.4591\n",
      "\n",
      "Epoch 00013: val_f1_score improved from 0.45765 to 0.45914, saving model to ../models/weights/text_inception-13-0.4591-0.1018.hdf5\n",
      "Epoch 14/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1199 - f1_score: 0.3256 - val_loss: 0.0992 - val_f1_score: 0.4675\n",
      "\n",
      "Epoch 00014: val_f1_score improved from 0.45914 to 0.46753, saving model to ../models/weights/text_inception-14-0.4675-0.0992.hdf5\n",
      "Epoch 15/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1194 - f1_score: 0.3250 - val_loss: 0.0958 - val_f1_score: 0.4780\n",
      "\n",
      "Epoch 00015: val_f1_score improved from 0.46753 to 0.47800, saving model to ../models/weights/text_inception-15-0.4780-0.0958.hdf5\n",
      "Epoch 16/60\n",
      "9587/9587 [==============================] - 59s 6ms/step - loss: 0.1175 - f1_score: 0.3390 - val_loss: 0.0964 - val_f1_score: 0.4541\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.47800\n",
      "Epoch 17/60\n",
      "9587/9587 [==============================] - 63s 7ms/step - loss: 0.1164 - f1_score: 0.3477 - val_loss: 0.0948 - val_f1_score: 0.4781\n",
      "\n",
      "Epoch 00017: val_f1_score improved from 0.47800 to 0.47807, saving model to ../models/weights/text_inception-17-0.4781-0.0948.hdf5\n",
      "Epoch 18/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1156 - f1_score: 0.3472 - val_loss: 0.0929 - val_f1_score: 0.4687\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.47807\n",
      "Epoch 19/60\n",
      "9587/9587 [==============================] - 66s 7ms/step - loss: 0.1147 - f1_score: 0.3540 - val_loss: 0.0935 - val_f1_score: 0.4637\n",
      "\n",
      "Epoch 00019: val_f1_score did not improve from 0.47807\n",
      "Epoch 20/60\n",
      "9587/9587 [==============================] - 65s 7ms/step - loss: 0.1144 - f1_score: 0.3539 - val_loss: 0.0923 - val_f1_score: 0.4786\n",
      "\n",
      "Epoch 00020: val_f1_score improved from 0.47807 to 0.47861, saving model to ../models/weights/text_inception-20-0.4786-0.0923.hdf5\n",
      "Epoch 21/60\n",
      "9587/9587 [==============================] - 53s 5ms/step - loss: 0.1130 - f1_score: 0.3648 - val_loss: 0.0928 - val_f1_score: 0.4672\n",
      "\n",
      "Epoch 00021: val_f1_score did not improve from 0.47861\n",
      "Epoch 22/60\n",
      "9587/9587 [==============================] - 64s 7ms/step - loss: 0.1120 - f1_score: 0.3736 - val_loss: 0.0919 - val_f1_score: 0.4767\n",
      "\n",
      "Epoch 00022: val_f1_score did not improve from 0.47861\n",
      "Epoch 23/60\n",
      "3584/9587 [==========>...................] - ETA: 40s - loss: 0.1121 - f1_score: 0.3773"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    model = get_text_inception()\n",
    "    # model.load_weights('../models/weights/text_inception-06-0.6097-0.0697.hdf5')\n",
    "    filepath=\"../models/weights/text_inception-{epoch:02d}-{val_f1_score:.4f}-{val_loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_f1_score', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "    model.fit(X_train, y_train, epochs=60, batch_size = 16, validation_split=0.33, \n",
    "              callbacks=[checkpoint],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_text_inception()\n",
    " \n",
    "model.load_weights('../models/weights/text_inception-37-0.6099-0.0679.hdf5')\n",
    "pred4  = model.predict(X_test, batch_size=1024)\n",
    "res, res_df = pred2res(pred4)\n",
    "res_df.head(50)\n",
    "np.savetxt('../data/output/text_inception_0.6099_679_1107.txt',pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('../data/output/submission/text_inception_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
