{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 635793 word vectors.\n",
      "19878\n",
      "(8288, 100) (2364, 100) (8288, 30)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://github.com/312shan/Subject-and-Sentiment-Analysis\n",
    "\"\"\"\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "from capsule import *\n",
    "import jieba\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, SpatialDropout2D, Activation, Embedding, Flatten, Conv2D, MaxPool2D\n",
    " \n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Reshape, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import numpy as np\n",
    "from keras.layers import BatchNormalization\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import numpy as np\n",
    "# not enable in windows\n",
    "# jieba.enable_parallel(4)\n",
    "from utils import *\n",
    "K.clear_session()\n",
    "\n",
    "test_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_size == 0:\n",
    "    X_train = '../data/output/matrixes/X_train'\n",
    "    y_train = '../data/output/matrixes/y_train'\n",
    "    X_test = '../data/output/matrixes/X_dev'\n",
    "\n",
    "else:\n",
    "    stop_words = load_stop_words()\n",
    "    embeddings_index = load_embeddings_index()\n",
    "    embedding_matrix = get_embedding_matrix(word2index, embeddings_index)  # word-index-embedding是它们之间的链接关系\n",
    "    seqs_train, seqs_valid, seqs_dev, word2index, y_train, y_valid, train_id_label_dict, valid_label = raw_file_2_matrix(train_file, test_file, stop_words, test_size=test_size)\n",
    "    X_train, X_valid, X_test = get_padding_data(seqs_train, seqs_valid, seqs_dev)  # seqs needs to be a list of a list.把列表变成矩阵，列数是embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_cnn_model():\n",
    "    # 加残差或者是attention\n",
    "    # 3个串联  0.10\n",
    "    drop = 0.60# 0.55\n",
    "    # dropout_p = 0.5\n",
    "    learning_rate = 0.005  # 0.0001\n",
    "    Dim_capsule = 30 # 128\n",
    "    gru_units= Dim_capsule>>1\n",
    "    inputs = Input(shape=(maxlen,))\n",
    "    embed_layer = Embedding(len(word2index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "                            input_length=maxlen, trainable=False)(inputs)\n",
    "    embed_layer = SpatialDropout1D(drop)(embed_layer)\n",
    "     \n",
    " \n",
    "    capsule1 = Capsule(num_capsule=Num_capsule, dim_capsule=Dim_capsule, routings=Routings, # kernel_size=(3, 1),\n",
    "                      share_weights=True)(embed_layer)\n",
    "    bn1 = BatchNormalization()(capsule1)\n",
    "                                    \n",
    "\n",
    "    x1 = Bidirectional(GRU(gru_units, activation='relu', dropout=dropout_p, recurrent_dropout=dropout_p, \n",
    "                          return_sequences=True))(embed_layer)\n",
    "    print(bn1.shape, x1.shape)                                      \n",
    "    concat = Concatenate(axis=1)([bn1, x1])\n",
    "    bn = Flatten()(concat)\n",
    "\n",
    "    fc = Dense(300)(bn)\n",
    "    bn = BatchNormalization()(fc)\n",
    "    bn = Activation('relu')(bn)\n",
    "    bn_dropout = Dropout(drop)(bn)\n",
    "    outputs = Dense(30, activation=\"sigmoid\")(bn_dropout)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "    # validation_data=(p_X_test, p_y_test))\n",
    "    # score, acc = model.evaluate(p_X_test, p_y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10, 30) (?, ?, 30)\n",
      "Train on 7459 samples, validate on 829 samples\n",
      "Epoch 1/24\n",
      "7459/7459 [==============================] - 51s 7ms/step - loss: 0.1878 - acc: 0.9455 - val_loss: 0.1006 - val_acc: 0.9721\n",
      "Epoch 2/24\n",
      "7459/7459 [==============================] - 41s 5ms/step - loss: 0.1282 - acc: 0.9633 - val_loss: 0.0739 - val_acc: 0.9751\n",
      "Epoch 3/24\n",
      "7459/7459 [==============================] - 39s 5ms/step - loss: 0.1126 - acc: 0.9650 - val_loss: 0.0684 - val_acc: 0.9763\n",
      "Epoch 4/24\n",
      "7459/7459 [==============================] - 47s 6ms/step - loss: 0.1081 - acc: 0.9658 - val_loss: 0.0652 - val_acc: 0.9764\n",
      "Epoch 5/24\n",
      "7459/7459 [==============================] - 49s 7ms/step - loss: 0.1024 - acc: 0.9666 - val_loss: 0.0646 - val_acc: 0.9769\n",
      "Epoch 6/24\n",
      "7459/7459 [==============================] - 49s 7ms/step - loss: 0.0988 - acc: 0.9674 - val_loss: 0.0634 - val_acc: 0.9767\n",
      "Epoch 7/24\n",
      "7459/7459 [==============================] - 50s 7ms/step - loss: 0.0955 - acc: 0.9681 - val_loss: 0.0628 - val_acc: 0.9767\n",
      "Epoch 8/24\n",
      "7459/7459 [==============================] - 50s 7ms/step - loss: 0.0936 - acc: 0.9681 - val_loss: 0.0620 - val_acc: 0.9775\n",
      "Epoch 9/24\n",
      "7459/7459 [==============================] - 49s 7ms/step - loss: 0.0902 - acc: 0.9688 - val_loss: 0.0623 - val_acc: 0.9769\n",
      "Epoch 10/24\n",
      "7459/7459 [==============================] - 49s 7ms/step - loss: 0.0871 - acc: 0.9690 - val_loss: 0.0622 - val_acc: 0.9769\n",
      "Epoch 11/24\n",
      "7459/7459 [==============================] - 50s 7ms/step - loss: 0.0856 - acc: 0.9696 - val_loss: 0.0628 - val_acc: 0.9768\n",
      "Epoch 12/24\n",
      "7459/7459 [==============================] - 49s 7ms/step - loss: 0.0827 - acc: 0.9706 - val_loss: 0.0627 - val_acc: 0.9764\n",
      "Epoch 13/24\n",
      "7459/7459 [==============================] - 50s 7ms/step - loss: 0.0816 - acc: 0.9709 - val_loss: 0.0641 - val_acc: 0.9764\n",
      "Epoch 14/24\n",
      "7459/7459 [==============================] - 49s 7ms/step - loss: 0.0788 - acc: 0.9714 - val_loss: 0.0645 - val_acc: 0.9759\n",
      "Epoch 15/24\n",
      "7459/7459 [==============================] - 49s 7ms/step - loss: 0.0760 - acc: 0.9723 - val_loss: 0.0650 - val_acc: 0.9755\n",
      "Epoch 16/24\n",
      "7459/7459 [==============================] - 50s 7ms/step - loss: 0.0753 - acc: 0.9724 - val_loss: 0.0670 - val_acc: 0.9752\n",
      "Epoch 17/24\n",
      "7459/7459 [==============================] - 49s 7ms/step - loss: 0.0718 - acc: 0.9736 - val_loss: 0.0676 - val_acc: 0.9755\n",
      "Epoch 18/24\n",
      "7459/7459 [==============================] - 50s 7ms/step - loss: 0.0709 - acc: 0.9739 - val_loss: 0.0672 - val_acc: 0.9756\n",
      "Epoch 19/24\n",
      "7459/7459 [==============================] - 50s 7ms/step - loss: 0.0683 - acc: 0.9752 - val_loss: 0.0688 - val_acc: 0.9754\n",
      "Epoch 20/24\n",
      "7459/7459 [==============================] - 50s 7ms/step - loss: 0.0674 - acc: 0.9750 - val_loss: 0.0693 - val_acc: 0.9753\n",
      "Epoch 21/24\n",
      "7459/7459 [==============================] - 49s 7ms/step - loss: 0.0656 - acc: 0.9760 - val_loss: 0.0704 - val_acc: 0.9747\n",
      "Epoch 22/24\n",
      "7459/7459 [==============================] - 49s 7ms/step - loss: 0.0641 - acc: 0.9764 - val_loss: 0.0701 - val_acc: 0.9749\n",
      "Epoch 23/24\n",
      "7459/7459 [==============================] - 50s 7ms/step - loss: 0.0625 - acc: 0.9767 - val_loss: 0.0713 - val_acc: 0.9744\n",
      "Epoch 24/24\n",
      "7459/7459 [==============================] - 50s 7ms/step - loss: 0.0615 - acc: 0.9771 - val_loss: 0.0730 - val_acc: 0.9748\n",
      "(?, 10, 30) (?, ?, 30)\n",
      "Train on 7459 samples, validate on 829 samples\n",
      "Epoch 1/24\n",
      "7459/7459 [==============================] - 61s 8ms/step - loss: 0.1873 - acc: 0.9455 - val_loss: 0.0981 - val_acc: 0.9741\n",
      "Epoch 2/24\n",
      "1648/7459 [=====>........................] - ETA: 37s - loss: 0.1387 - acc: 0.9614"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c67b4cb70fa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# batch_size: 16, epochs = 15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfirst_model_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "first_model_results = []\n",
    "for i in range(2):\n",
    "    log_filepath = './tmp/log' \n",
    "    callback = [keras.callbacks.TensorBoard(log_dir=log_filepath, write_images=1, histogram_freq=1)]\n",
    "    model = get_text_cnn_model()\n",
    "    model.fit(X_train, y_train, batch_size=16, shuffle=True, epochs=10, \n",
    "              callbacks=callback, validation_data=(X_valid, y_valid))  # batch_size: 16, epochs = 15\n",
    "    first_model_results.append(model.predict(X_dev, batch_size=1024))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = np.average(first_model_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('../data/output/submission/ck2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/output/text_cnn.txt', pred4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
